{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bc8786-3ea7-4b21-a53f-09675d86534b",
   "metadata": {},
   "source": [
    "# Introduction to Snowpark pandas\n",
    "The Snowpark pandas API allows you to run your pandas code directly on your data in Snowflake. Built to replicate the functionality of pandas - including its data isolation and consistency guarantees - the Snowpark pandas API enables you to scale up your traditional pandas pipelines with just a few lines of change.\n",
    "\n",
    "In today's demo, we'll show how you can get started with the Snowpark pandas API. We'll also see that the Snowpark pandas API is very similar to the native pandas API. The results in this notebook come from comparing 1) Snowpark pandas version 1.15.0a1 on a newly created Snowflake warehouse of size 2-XL to 2) pandas 2.2.1 running on macOS Sonoma 14.4.1 on a MacBook Pro with 64 GB memory and an Apple M2 Max CPU.\n",
    "\n",
    "## Importing Snowpark pandas\n",
    "Much like Snowpark, Snowpark pandas requires an active `Session` object to connect to your data in Snowflake. In the next cell, we'll be initializing a Session object, and importing both Snowpark pandas and native pandas, as `spd` and `pd` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9388c10-9876-47a2-82a6-da35d120ff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Snowpark pandas is currently in Private Preview. See https://docs.snowflake.com/LIMITEDACCESS/snowpark-pandas for details.\n"
     ]
    }
   ],
   "source": [
    "import modin.pandas as spd\n",
    "import snowflake.snowpark.modin.plugin\n",
    "import pandas as pd\n",
    "import json\n",
    "from snowflake.snowpark import Session\n",
    "# Create Snowflake Session object\n",
    "from pathlib import Path\n",
    "import sys\n",
    "connection_parameters_path = str(Path(\"__file__\").absolute().parent.parent.parent.parent)\n",
    "sys.path.append(connection_parameters_path)\n",
    "from tests.parameters import CONNECTION_PARAMETERS\n",
    "\n",
    "session = Session.builder.configs(CONNECTION_PARAMETERS).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3812257-0a82-43a0-aaac-d00681558890",
   "metadata": {},
   "source": [
    "## Getting Started - Reading Data from Snowflake\n",
    "Today, we'll be analyzing some Stock Timeseries Data from Snowflake's Marketplace. The data is available courtesy of Cybersyn Inc., and can be found [here](https://app.snowflake.com/marketplace/listing/GZTSZAS2KF7/cybersyn-inc-financial-economic-essentials). Let's start by reading the `stock_price_timeseries` table into a DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03298234-aabe-4548-99b1-bfdb609bdafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 9.748766167000001 seconds to read a table with 66061030 rows into Snowpark pandas!\n"
     ]
    }
   ],
   "source": [
    "# Read data into a Snowpark pandas df \n",
    "from time import perf_counter\n",
    "start = perf_counter()\n",
    "spd_df = spd.read_snowflake(\"FINANCIAL__ECONOMIC_ESSENTIALS.CYBERSYN.STOCK_PRICE_TIMESERIES\")\n",
    "end = perf_counter()\n",
    "data_size = len(spd_df)\n",
    "print(f\"Took {end - start} seconds to read a table with {data_size} rows into Snowpark pandas!\")\n",
    "snow_time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ac2fd-c636-4bb5-a27d-58a5e4cbea7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read data into a local native pandas df - recommended to kill this cell after waiting a few minutes!\n",
    "\n",
    "from IPython import display\n",
    "start = perf_counter()\n",
    "\n",
    "# Create a cursor object.\n",
    "cur = session.connection.cursor()\n",
    "\n",
    "# Execute a statement that will generate a result set.\n",
    "sql = \"select * from FINANCIAL__ECONOMIC_ESSENTIALS.CYBERSYN.STOCK_PRICE_TIMESERIES\"\n",
    "cur.execute(sql)\n",
    "\n",
    "# Fetch the result set from the cursor and deliver it as the pandas DataFrame.\n",
    "native_pd_df = cur.fetch_pandas_all()\n",
    "end = perf_counter()\n",
    "print(f\"Native pandas took {end - start} seconds to read the data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72085630-11c4-4df1-9627-7c50c0957906",
   "metadata": {},
   "source": [
    "It takes much longer for native pandas to read the table into memory than for Snowpark pandas to read the table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c3dee5-62fe-46c6-a216-133a0140222d",
   "metadata": {},
   "source": [
    "## Examine The Raw Data\n",
    "Let's take a look at the data we're going to be working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a623bed-aed9-4cdb-a3c8-33e9e7da52af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICKER</th>\n",
       "      <th>ASSET_CLASS</th>\n",
       "      <th>PRIMARY_EXCHANGE_CODE</th>\n",
       "      <th>PRIMARY_EXCHANGE_NAME</th>\n",
       "      <th>VARIABLE</th>\n",
       "      <th>VARIABLE_NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDF</td>\n",
       "      <td>ETF-Index Fund Shares</td>\n",
       "      <td>PSE</td>\n",
       "      <td>NYSE ARCA</td>\n",
       "      <td>pre-market_open</td>\n",
       "      <td>Pre-Market Open</td>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>35.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATLC</td>\n",
       "      <td>Equity</td>\n",
       "      <td>NAS</td>\n",
       "      <td>NASDAQ CAPITAL MARKET</td>\n",
       "      <td>pre-market_open</td>\n",
       "      <td>Pre-Market Open</td>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>27.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPR</td>\n",
       "      <td>ETF-Index Fund Shares</td>\n",
       "      <td>BAT</td>\n",
       "      <td>BATS Z-EXCHANGE</td>\n",
       "      <td>pre-market_open</td>\n",
       "      <td>Pre-Market Open</td>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>24.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEL</td>\n",
       "      <td>Equity</td>\n",
       "      <td>NYS</td>\n",
       "      <td>NEW YORK STOCK EXCHANGE</td>\n",
       "      <td>pre-market_open</td>\n",
       "      <td>Pre-Market Open</td>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>142.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CYTH</td>\n",
       "      <td>Equity</td>\n",
       "      <td>NAS</td>\n",
       "      <td>NASDAQ CAPITAL MARKET</td>\n",
       "      <td>pre-market_open</td>\n",
       "      <td>Pre-Market Open</td>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>1.530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TICKER            ASSET_CLASS PRIMARY_EXCHANGE_CODE  \\\n",
       "0   INDF  ETF-Index Fund Shares                   PSE   \n",
       "1   ATLC                 Equity                   NAS   \n",
       "2   AAPR  ETF-Index Fund Shares                   BAT   \n",
       "3    TEL                 Equity                   NYS   \n",
       "4   CYTH                 Equity                   NAS   \n",
       "\n",
       "     PRIMARY_EXCHANGE_NAME         VARIABLE    VARIABLE_NAME        DATE  \\\n",
       "0                NYSE ARCA  pre-market_open  Pre-Market Open  2024-05-08   \n",
       "1    NASDAQ CAPITAL MARKET  pre-market_open  Pre-Market Open  2024-05-08   \n",
       "2          BATS Z-EXCHANGE  pre-market_open  Pre-Market Open  2024-05-08   \n",
       "3  NEW YORK STOCK EXCHANGE  pre-market_open  Pre-Market Open  2024-05-08   \n",
       "4    NASDAQ CAPITAL MARKET  pre-market_open  Pre-Market Open  2024-05-08   \n",
       "\n",
       "     VALUE  \n",
       "0   35.965  \n",
       "1   27.670  \n",
       "2   24.650  \n",
       "3  142.600  \n",
       "4    1.530  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spd_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822e6ae-9810-4ca1-8646-660eb3e68d97",
   "metadata": {},
   "source": [
    "## Filtering The Data\n",
    "Let's take a look at some common data transformations - starting with filtering! Let's filter for stocks that are listed on the New York Stock Exchange!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4218fceb-68f1-41be-8c08-3f6ad51424d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for stocks belonging to the NYSE took 1.480584958999998 seconds in Snowpark pandas\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "nyse_spd_df = spd_df[(spd_df['PRIMARY_EXCHANGE_CODE'] == 'NYS')]\n",
    "repr(nyse_spd_df)\n",
    "end = perf_counter()\n",
    "print(f\"Filtering for stocks belonging to the NYSE took {end - start} seconds in Snowpark pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e325b5-8e24-4dbc-93da-c2e93d84590f",
   "metadata": {},
   "source": [
    "Let's try an even more granular filter - let's filter for the Pre-Market Open of stocks that have the following tickers:\n",
    "* GOOG (Alphabet, Inc.)\n",
    "* MSFT (Microsoft)\n",
    "* SNOW (Snowflake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d456c29-7689-4599-bcd6-02c646ef8f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for the Pre-Market Open price for the above stocks took 1.0095136250000678 seconds in Snowpark pandas\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "filtered_spd_df = spd_df[((spd_df['TICKER'] == 'GOOG') | (spd_df['TICKER'] == 'MSFT') | (spd_df['TICKER'] == 'SNOW')) & (spd_df['VARIABLE_NAME'] == 'Pre-Market Open')]\n",
    "repr(filtered_spd_df)\n",
    "end = perf_counter()\n",
    "print(f\"Filtering for the Pre-Market Open price for the above stocks took {end - start} seconds in Snowpark pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d5cb07-ccce-481e-b41e-770d4de91b0f",
   "metadata": {},
   "source": [
    "# Reshaping the Data\n",
    "Let's say we wanted to analyse the performance of various stock prices across time - in that case, it may be more helpful to have the values as columns, and the ticker name and date as the index - rather than the current encoding. We can accomplish this using the `pivot_table` API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f8f893a-c7dc-4e08-bace-3c93ada282cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoting the DataFrame took 4.195186291000027 seconds in Snowpark pandas\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "reshape_df = spd_df.pivot_table(index=[\"TICKER\", \"DATE\"], columns=\"VARIABLE_NAME\", values=\"VALUE\")\n",
    "repr(reshape_df)\n",
    "end = perf_counter()\n",
    "print(f\"Pivoting the DataFrame took {end - start} seconds in Snowpark pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c0b9d1-a3be-4d05-9481-f54628f3b793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VARIABLE_NAME</th>\n",
       "      <th>All-Day High</th>\n",
       "      <th>All-Day Low</th>\n",
       "      <th>Nasdaq Volume</th>\n",
       "      <th>Post-Market Close</th>\n",
       "      <th>Pre-Market Open</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TICKER</th>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>66.35</td>\n",
       "      <td>65.50</td>\n",
       "      <td>439231.0</td>\n",
       "      <td>66.23</td>\n",
       "      <td>65.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-02</th>\n",
       "      <td>66.86</td>\n",
       "      <td>65.81</td>\n",
       "      <td>316586.0</td>\n",
       "      <td>65.91</td>\n",
       "      <td>66.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03</th>\n",
       "      <td>66.46</td>\n",
       "      <td>64.85</td>\n",
       "      <td>407491.0</td>\n",
       "      <td>66.33</td>\n",
       "      <td>65.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04</th>\n",
       "      <td>67.25</td>\n",
       "      <td>65.63</td>\n",
       "      <td>269025.0</td>\n",
       "      <td>66.99</td>\n",
       "      <td>66.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-07</th>\n",
       "      <td>67.98</td>\n",
       "      <td>67.08</td>\n",
       "      <td>263454.0</td>\n",
       "      <td>67.40</td>\n",
       "      <td>67.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "VARIABLE_NAME      All-Day High  All-Day Low  Nasdaq Volume  \\\n",
       "TICKER DATE                                                   \n",
       "A      2018-05-01         66.35        65.50       439231.0   \n",
       "       2018-05-02         66.86        65.81       316586.0   \n",
       "       2018-05-03         66.46        64.85       407491.0   \n",
       "       2018-05-04         67.25        65.63       269025.0   \n",
       "       2018-05-07         67.98        67.08       263454.0   \n",
       "\n",
       "VARIABLE_NAME      Post-Market Close  Pre-Market Open  \n",
       "TICKER DATE                                            \n",
       "A      2018-05-01              66.23            65.64  \n",
       "       2018-05-02              65.91            66.01  \n",
       "       2018-05-03              66.33            65.91  \n",
       "       2018-05-04              66.99            66.06  \n",
       "       2018-05-07              67.40            67.16  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3121c325-d7cf-47d6-a2d7-e759ece59d11",
   "metadata": {},
   "source": [
    "## Transforming the Data\n",
    "Now that we have reformatted the data, we can beginn to apply some transformations. Let's start by taking a look at the All-Day Low column for the tickers above - we can resample the data to look at the Quarterly Low for the `GOOG` ticker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b06f23b-12dc-4387-bb87-bc4cbcff6a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling the DataFrame took 2.099826750000034 seconds in Snowpark pandas\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "resampled_spd_df_all_quarter_low = reshape_df[\"All-Day Low\"][\"GOOG\"].resample(\"91D\").min()\n",
    "repr(resampled_spd_df_all_quarter_low)\n",
    "end = perf_counter()\n",
    "print(f\"Resampling the DataFrame took {end - start} seconds in Snowpark pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8978f55a-c28a-4b7f-9f20-4a2952d2a857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE\n",
       "2018-05-01    1006.48\n",
       "2018-07-31     995.58\n",
       "2018-10-30     968.09\n",
       "2019-01-29    1055.85\n",
       "2019-04-30    1025.06\n",
       "2019-07-30    1125.00\n",
       "2019-10-29    1250.79\n",
       "2020-01-28    1013.54\n",
       "2020-04-28    1218.04\n",
       "2020-07-28    1399.96\n",
       "2020-10-27    1514.61\n",
       "2021-01-26    1801.22\n",
       "2021-04-27    2223.89\n",
       "2021-07-27    2623.00\n",
       "2021-10-26    2493.01\n",
       "2022-01-25    2363.60\n",
       "2022-04-26     107.01\n",
       "2022-07-26      94.93\n",
       "2022-10-25      83.00\n",
       "2023-01-24      88.87\n",
       "2023-04-25     101.66\n",
       "2023-07-25     121.54\n",
       "2023-10-24     121.47\n",
       "2024-01-23     131.54\n",
       "2024-04-23     152.77\n",
       "Freq: None, Name: All-Day Low, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_spd_df_all_quarter_low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c512e74d-7316-44de-a644-917270d38fac",
   "metadata": {},
   "source": [
    "We can even take a look at the quarter-over-quarter fluctuation in prices using the `diff` API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb467dd6-cc74-423f-b17b-46541f5bbff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffing the resampled data took 0.6961409589999903 seconds in Snowpark pandas\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "q_o_q_resampled_spd_df_all_quarter_low = resampled_spd_df_all_quarter_low.diff()\n",
    "repr(q_o_q_resampled_spd_df_all_quarter_low)\n",
    "end = perf_counter()\n",
    "print(f\"Diffing the resampled data took {end - start} seconds in Snowpark pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866628d5-5bf9-4212-bba2-bf5e816a70e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE\n",
       "2018-05-01        NaN\n",
       "2018-07-31     -10.90\n",
       "2018-10-30     -27.49\n",
       "2019-01-29      87.76\n",
       "2019-04-30     -30.79\n",
       "2019-07-30      99.94\n",
       "2019-10-29     125.79\n",
       "2020-01-28    -237.25\n",
       "2020-04-28     204.50\n",
       "2020-07-28     181.92\n",
       "2020-10-27     114.65\n",
       "2021-01-26     286.61\n",
       "2021-04-27     422.67\n",
       "2021-07-27     399.11\n",
       "2021-10-26    -129.99\n",
       "2022-01-25    -129.41\n",
       "2022-04-26   -2256.59\n",
       "2022-07-26     -12.08\n",
       "2022-10-25     -11.93\n",
       "2023-01-24       5.87\n",
       "2023-04-25      12.79\n",
       "2023-07-25      19.88\n",
       "2023-10-24      -0.07\n",
       "2024-01-23      10.07\n",
       "2024-04-23      21.23\n",
       "Freq: None, Name: All-Day Low, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_o_q_resampled_spd_df_all_quarter_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7593697-feb5-40a7-9d6c-7c011ad35186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Conclusion\n",
       "As we can see, Snowpark pandas is able to replicate the pandas API while performing computations on large data sets that don't typically work with native pandas and all while keeping your data in Snowflake!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.Markdown(data=f\"\"\"## Conclusion\\nAs we can see, Snowpark pandas is able to replicate the pandas API while performing computations on large data sets that don't typically work with native pandas and all while keeping your data in Snowflake!\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d385589-1f03-4603-b2a1-54f144c20f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
