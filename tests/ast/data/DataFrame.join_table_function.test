## TEST CASE

df1 = session.create_dataframe(
    [
        ["foo", "The quick brown fox jumps over the lazy dog"],
        ["bar", "Lorem ipsum dolor sit amet, consectetur adipiscing elit"],
    ],
    schema=["name", "text"],
)

df2 = df1.join_table_function("STRTOK_SPLIT_TO_TABLE", df1["text"], lit(" "))

tokenize_text = (
    call_table_function("STRTOK_SPLIT_TO_TABLE", df1["text"], lit(" "))
    .over(partition_by="name")
    .over(order_by="text")
    .alias("ignored1", "ignored2", "ignored3")
    .alias("original_row_number", "token_number", "token")
)

df3 = df1.join_table_function(tokenize_text)

df3 = df1.join_table_function(tokenize_text)

tokenize_text_ref = table_function("STRTOK_SPLIT_TO_TABLE")
df4 = df1.join_table_function(
    tokenize_text_ref(df1["text"], lit(" "))
    .over(partition_by="name", order_by="text")
    .alias("original_row_number", "token_number", "token")
)

df5 = df1.join_table_function(
    tokenize_text_ref(df1["text"], lit(" ,"))
    .over(partition_by="name", order_by="text")
    .alias("row_number", "token_number", "token")
)

## EXPECTED UNPARSER OUTPUT

## EXPECTED ENCODED AST
