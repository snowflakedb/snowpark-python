{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014b3af4-af71-4b9d-b6f4-c8f990c11d62",
   "metadata": {},
   "source": [
    "# Hybrid Execution Build Verification Test\n",
    "\n",
    "In this demo, we will show how you can develop a robust pandas pipelines at all data scales. You will see how pandas on Snowflake intelligently determines whether to execute queries locally with regular pandas or run directly in Snowflake. This allows you to rapidly iterate with your pandas workflows for testing and development on small datasets, while futureproofing your pipelines when you scale up to production data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f420d4-a934-409c-92b9-29d2427ce6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://snowbiz.okta.com/app/snowflake/exk8wfsfryJIn4IWZ2p7/sso/saml?SAMLRequest=jVJdc9owEPwrHvUZSzbOBDRAhoQQ3BKgfCQzeRO2TFTLktHJceivr8xHJ31Ipm%2Ba0%2B7t3u31bt4L6b1xA0KrPgp8gjyuEp0KteujzXrc6iAPLFMpk1rxPjpwQDeDHrBClnRY2Ve15PuKg%2FVcIwW0%2BeijyiiqGQigihUcqE3oavg4paFPKAPgxjo5dKakIJzWq7Ulxbiua79u%2B9rscEgIwaSLHaqBfEMfJMqvNUqjrU60vFDe3UyfSASYRI2EQziFxZl4K9RpBV%2BpbE8goJP1etFazFdr5A0v091pBVXBzYqbN5HwzXJ6MgDOwWo2f57MN6t7H5SuM8lynuiirKzr5rsXzniKpd4Jt6N41EdlLtLr%2FdJUP0iyZdFoej9rF%2Fn8YSz3w1%2B5nHRTwZ7yn8lDxm6tihLkPV0SDZtEY4CKx6rJ0boSCa9aJGoFV%2BuQUNKlUccnQfsFeSOXo1DMHpkXs43Frfjt69yyozlWlvivb8zf806dQWYO32MVxc8vYXmNATRuYkKnS6FHA2bwv%2FP38EfW%2Bdhmbv%2FxaKGlSA7eWJuC2c%2FjCfzgWBFpKztCKS%2BYkMM0NRzAxSSlru8MZ9bdtDUVR3hwUv33qgd%2FAA%3D%3D&RelayState=ver%3A1-hint%3A2050423465438-ETMsDgAAAZY7EnbtABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAEAVaNTQ9y5wyJ0RHiBLIoJ4AAACQ48WHHGDd1Wi1qq7Rf%2F6kBxy4kEgD729WA6%2BQWHROunTPyM9dr2evQtplQB%2FawADvysWR%2F07JUA1FKrO3kVw3I%2BjCcp07PhtkuPJu70jWaz7eQGrPnqmLw1gP1GDCP5Q9nnzyQ79IpbBkfpl5GQV7vbpRJGANgC5VpD7WAgwk9OO8n7py1s6fCqCFFTfXus%2BXABRNc0Os1vCY1aPGDKcUq2cPXuT4Bw%3D%3D to authenticate...\n"
     ]
    }
   ],
   "source": [
    "import snowflake.snowpark.modin.plugin\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as native_pd\n",
    "from time import perf_counter\n",
    "from snowflake.snowpark.session import Session; session = Session.builder.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662115d3-ad0a-4fea-88ba-321a03ffdf3c",
   "metadata": {},
   "source": [
    "## Example 1: Working with small/inline-created dataframe is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad6a86c-ba58-443e-b48f-80a717eb8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_holidays = [\n",
    "    (\"New Year's Day\", \"2025-01-01\"),\n",
    "    (\"Martin Luther King Jr. Day\", \"2025-01-20\"),\n",
    "    (\"Presidents' Day\", \"2025-02-17\"),\n",
    "    (\"Memorial Day\", \"2025-05-26\"),\n",
    "    (\"Juneteenth National Independence Day\", \"2025-06-19\"),\n",
    "    (\"Independence Day\", \"2025-07-04\"),\n",
    "    (\"Labor Day\", \"2025-09-01\"),\n",
    "    (\"Columbus Day\", \"2025-10-13\"),\n",
    "    (\"Veterans Day\", \"2025-11-11\"),\n",
    "    (\"Thanksgiving Day\", \"2025-11-27\"),\n",
    "    (\"Christmas Day\", \"2025-12-25\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_us_holidays = pd.DataFrame(us_holidays, columns=[\"Holiday\", \"Date\"])\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df_us_holidays[\"Date\"] = pd.to_datetime(df_us_holidays[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de09f690-e4e6-4aa3-bef5-bc96a389c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_us_holidays.get_backend() == 'Pandas'  # with auto, we should expect this to be local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f05b150e-086f-4337-bd50-25db48bbeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns for transformations\n",
    "df_us_holidays[\"Day_of_Week\"] = df_us_holidays[\"Date\"].dt.day_name()\n",
    "df_us_holidays[\"Month\"] = df_us_holidays[\"Date\"].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d304c3-54bc-4ab0-b792-df0e67566819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "      <td>2025-01-20</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Presidents' Day</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>Monday</td>\n",
       "      <td>February</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Memorial Day</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>Monday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juneteenth National Independence Day</td>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Independence Day</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Friday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Labor Day</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>September</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Columbus Day</td>\n",
       "      <td>2025-10-13</td>\n",
       "      <td>Monday</td>\n",
       "      <td>October</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Veterans Day</td>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thanksgiving Day</td>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Holiday       Date Day_of_Week      Month\n",
       "0                         New Year's Day 2025-01-01   Wednesday    January\n",
       "1             Martin Luther King Jr. Day 2025-01-20      Monday    January\n",
       "2                        Presidents' Day 2025-02-17      Monday   February\n",
       "3                           Memorial Day 2025-05-26      Monday        May\n",
       "4   Juneteenth National Independence Day 2025-06-19    Thursday       June\n",
       "5                       Independence Day 2025-07-04      Friday       July\n",
       "6                              Labor Day 2025-09-01      Monday  September\n",
       "7                           Columbus Day 2025-10-13      Monday    October\n",
       "8                           Veterans Day 2025-11-11     Tuesday   November\n",
       "9                       Thanksgiving Day 2025-11-27    Thursday   November\n",
       "10                         Christmas Day 2025-12-25    Thursday   December"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558479c6-11d3-42f0-990a-7914967ab66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Year's Day falls on Wednesday, January 1, 2025.\n",
      "Martin Luther King Jr. Day falls on Monday, January 20, 2025.\n",
      "Presidents' Day falls on Monday, February 17, 2025.\n",
      "Memorial Day falls on Monday, May 26, 2025.\n",
      "Juneteenth National Independence Day falls on Thursday, June 19, 2025.\n",
      "Independence Day falls on Friday, July 4, 2025.\n",
      "Labor Day falls on Monday, September 1, 2025.\n",
      "Columbus Day falls on Monday, October 13, 2025.\n",
      "Veterans Day falls on Tuesday, November 11, 2025.\n",
      "Thanksgiving Day falls on Thursday, November 27, 2025.\n",
      "Christmas Day falls on Thursday, December 25, 2025.\n",
      "CPU times: user 89.8 ms, sys: 4.07 ms, total: 93.8 ms\n",
      "Wall time: 92.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Note that without auto-switching, this took 2.5 min\n",
    "for index, row in df_us_holidays.iterrows():\n",
    "    print(f\"{row['Holiday']} falls on {row['Day_of_Week']}, {row['Month']} {row['Date'].day}, {row['Date'].year}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aae1a0-98b3-4c3d-a5f4-4c8d183161a0",
   "metadata": {},
   "source": [
    "### 💡 Automatic switching speeds up loops/iterations on small data + inline creation of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88d966-cd81-400f-b0c5-ceac5731aeba",
   "metadata": {},
   "source": [
    "## Example 2: When data is filtered the choice of engine changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c6d9f6-6168-4f66-8441-5b3ea467e313",
   "metadata": {},
   "source": [
    "Run the following SQL to generate a synthetic dataset with 10M rows of transactions (from 2024-2025 current date)\n",
    "```sql\n",
    "CREATE OR REPLACE TABLE revenue_transactions (\n",
    "    Transaction_ID STRING,\n",
    "    Date DATE,\n",
    "    Revenue FLOAT\n",
    ");\n",
    "\n",
    "SET num_days = (SELECT DATEDIFF(DAY, '2024-01-01', CURRENT_DATE));\n",
    "INSERT INTO revenue_transactions (Transaction_ID, Date, Revenue)\n",
    "SELECT\n",
    "    UUID_STRING() AS Transaction_ID,\n",
    "    DATEADD(DAY, UNIFORM(0, $num_days, RANDOM()), '2024-01-01') AS Date,\n",
    "    UNIFORM(10, 1000, RANDOM()) AS Revenue\n",
    "FROM TABLE(GENERATOR(ROWCOUNT => 10000000));\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da82055d-74ed-4ec6-b6cc-886753d10cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(number of rows inserted=10000000)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the following to generate a synthetic dataset with 10M rows of transactions (from 2024-2025 current date)\n",
    "session.sql('''\n",
    "CREATE OR REPLACE TABLE revenue_transactions (\n",
    "    Transaction_ID STRING,\n",
    "    Date DATE,\n",
    "    Revenue FLOAT\n",
    ");''').collect()\n",
    "session.sql('''SET num_days = (SELECT DATEDIFF(DAY, '2024-01-01', CURRENT_DATE));''').collect()\n",
    "session.sql('''INSERT INTO revenue_transactions (Transaction_ID, Date, Revenue)\n",
    "SELECT\n",
    "    UUID_STRING() AS Transaction_ID,\n",
    "    DATEADD(DAY, UNIFORM(0, $num_days, RANDOM()), '2024-01-01') AS Date,\n",
    "    UNIFORM(10, 1000, RANDOM()) AS Revenue\n",
    "FROM TABLE(GENERATOR(ROWCOUNT => 10000000));\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af2a3cd9-7d32-4242-a358-8dd5aee926dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switcheroo operation: read_snowflake cost to move to pandas: 1000 cost to stay: 250\n"
     ]
    }
   ],
   "source": [
    "df_transactions = pd.read_snowflake(\"REVENUE_TRANSACTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0227e992-54cb-4c72-8fc1-69b69f1c9570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset size is 10000000 and the data is located in Snowflake.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset size is {len(df_transactions)} and the data is located in {df_transactions.get_backend()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dafef83-ee11-4f60-b17b-ce84cc29d854",
   "metadata": {},
   "source": [
    "Perform some operations on 10M rows with Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9aa6dde-84db-41a8-9070-3d384a576f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions[\"DATE\"] = pd.to_datetime(df_transactions[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2ae5759-2d39-482c-9fbd-bd937c2fbdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switcheroo operation: sum cost to move to pandas: 1000 cost to stay: 250\n",
      "CPU times: user 15.4 ms, sys: 4.17 ms, total: 19.5 ms\n",
      "Wall time: 132 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DATE\n",
       "2024-01-01    10706581.0\n",
       "2024-01-02    10840213.0\n",
       "2024-01-03    10771250.0\n",
       "2024-01-04    10569984.0\n",
       "2024-01-05    10620351.0\n",
       "                 ...    \n",
       "2025-04-11    10741805.0\n",
       "2025-04-12    10690266.0\n",
       "2025-04-13    10750746.0\n",
       "2025-04-14    10766078.0\n",
       "2025-04-15    10740229.0\n",
       "Freq: None, Name: REVENUE, Length: 471, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_transactions.groupby(\"DATE\").sum()[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "824036de-5ac8-4990-8ab3-cd164c43eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions.get_backend() == \"Snowflake\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733779ec-13d5-4c24-a874-3d21dfc5e759",
   "metadata": {},
   "source": [
    "So far everything has been happening in Snowflake, since we are working with the full dataset (10M rows). \n",
    "Next, we demonstrate what happens when we filter the data down to a smaller dataset below our data size threshold for automatic engine switching. \n",
    "First, let's perform the filtering directly with pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23cbfe75-dd9e-4272-b466-fdb0cc0f9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_filter1 = df_transactions[(df_transactions[\"DATE\"] >= pd.Timestamp.today().date() - pd.Timedelta('7 days')) & (df_transactions[\"DATE\"] < pd.Timestamp.today().date())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc87088a-dc85-43f5-8e66-8be46074f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions_filter1.get_backend() == \"Snowflake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e454bdb7-2fff-4c52-ad18-6419e197dbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The current operation leads to materialization and can be slow if the data is large!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2025-04-08 to 2025-04-14. Resulting dataset size: 148485\n"
     ]
    }
   ],
   "source": [
    "print(f\"Date range: {df_transactions_filter1['DATE'].min().date()} to {df_transactions_filter1['DATE'].max().date()}. Resulting dataset size: {len(df_transactions_filter1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e416386-07f9-4604-940b-56923d73d463",
   "metadata": {},
   "source": [
    "Now that we have a smaller dataframe, this happens in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abcc6f90-f883-49a8-b850-3bf5cadd31a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 2 µs, total: 6 µs\n",
      "Wall time: 13.1 µs\n",
      "Switcheroo operation: sum cost to move to pandas: 37 cost to stay: 750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7daac87246407eaeb0ffbb28ff4c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transferring data from Snowflake to Pandas ...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time\n",
    "df_transactions_filter1 = df_transactions_filter1.groupby(\"DATE\").sum()[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1d151b6-1c48-4d27-a19b-c429abb48f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions_filter1.get_backend()==\"Pandas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d9f6c-dc87-42c7-8b3f-e19b36ea5897",
   "metadata": {},
   "source": [
    "We saw what happens when we filter with pandas. Now let's look at what happens if we perform filtering via SQL directly in the `read_snowflake` command, so the dataframe upon creation is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee902a-71d8-412b-83b7-ffbd53b8a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_filter2 = pd.read_snowflake(\"SELECT * FROM revenue_transactions WHERE Date >= DATEADD( 'days', -7, current_date ) and Date < current_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024f0ff-b9d7-4c67-9fba-e98b1336300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions_filter2.get_backend()==\"Pandas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf8150-97bb-479f-acb4-d0a4767037db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the result is same as above\n",
    "print(f\"Date range: {df_transactions_filter2['DATE'].min()} to {df_transactions_filter2['DATE'].max()}. Resulting dataset size: {len(df_transactions_filter2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5972d8e-d5d9-4583-8719-415b71f32a8c",
   "metadata": {},
   "source": [
    "Once you are in pandas, you can still continue to perform the same operations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6ea59-9f26-4968-b652-cac35850c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "df_transactions_filter2.groupby(\"DATE\").sum()[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f187ff8-dd87-4640-803e-0ca7e4867e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions_filter2.get_backend() == 'Pandas'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bba5b-6f50-48d8-85a4-189668a67fa8",
   "metadata": {},
   "source": [
    "### 💡 Automatic switching means that pandas work well for both small and large data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f641537-49d6-4e39-9d28-c9eaf1b1f6af",
   "metadata": {},
   "source": [
    "## Example 3: Combining small and large datasets in the same workflow\n",
    "\n",
    "Soemtimes you are working with multiple dataframes of different sizes and you need to join them together, what happens in this scenario?\n",
    "When two dataframes are joined and the two dataframe are coming from different engine, we automatically determine what is the most optimal way to move the data to minimize the cost of data movement.\n",
    "\n",
    "Continuing with our `df_transactions` and `df_us_holidays` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7514b5-d880-4f32-89a6-65360cfd2d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quick recap:\")\n",
    "print(f\"- df_transactions is {len(df_transactions)} rows and the data is located in {df_transactions.get_backend()}.\")\n",
    "print(f\"- df_us_holidays is {len(df_us_holidays)} rows and the data is located in {df_us_holidays.get_backend()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad40f90-255a-49aa-a267-493aa4ca7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions[\"DATE\"] = pd.to_datetime(df_transactions[\"DATE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272bf76-8aa6-449a-abb7-cfeff35d2cc2",
   "metadata": {},
   "source": [
    "Since `df_us_holidays` is much smaller than `df_transactions`, we moved `df_us_holidays` to Snowflake where `df_transactions` is, to perform the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f77864-eb02-4899-895d-a5f3fe907650",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.merge(df_us_holidays, df_transactions, left_on=\"Date\", right_on=\"DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe1e1e-1b79-4053-9aaf-c4a55896ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert combined.get_backend() == \"Snowflake\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b0dc6-96c5-4e7a-8e00-cc26281bccb0",
   "metadata": {},
   "source": [
    "### 💡 When we combine multiple dataframes running in different locations, pandas on Snowflake automatically determines where to move the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88cfe0-936a-4fa0-ba01-1a7152781d2f",
   "metadata": {},
   "source": [
    "## Example 4: Performing custom `apply` on small dataset\n",
    "\n",
    "apply is known to be slow in Snowpark pandas since it is implemented as UDF/UDTF, which often comes with a fixed startup time.\n",
    "Here, we show an example of how performing `apply` on a small dataset is faster with local pandas. \n",
    "\n",
    "In this example, we want to forecast using last year's transaction data via a custom apply function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7f0e1-3db6-4a6e-97f3-d28e8d28cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_revenue(df, start_date, end_date):\n",
    "    # Filter data from last year\n",
    "    df_filtered = df[(df[\"DATE\"] >= start_date - pd.Timedelta(days=365)) & (df[\"DATE\"] < start_date)]\n",
    "    \n",
    "    # Append future dates to daily_avg for prediction\n",
    "    future_dates = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "    df_future = pd.DataFrame({\"DATE\": future_dates})\n",
    "\n",
    "    # Group by DATE and calculate the mean revenue\n",
    "    daily_avg = df_filtered.groupby(\"DATE\")[\"REVENUE\"].mean().reset_index()\n",
    "    daily_avg[\"DATE\"] = daily_avg[\"DATE\"].astype('datetime64[ns]')\n",
    "    # Merge future dates with predicted revenue, filling missing values\n",
    "    df_forecast = df_future.merge(daily_avg, on=\"DATE\", how=\"left\")\n",
    "    import numpy as np\n",
    "    # Fill missing predicted revenue with overall mean from last year\n",
    "    df_forecast[\"PREDICTED_REVENUE\"] = np.nan\n",
    "    df_forecast[\"PREDICTED_REVENUE\"].fillna(daily_avg[\"REVENUE\"].mean(), inplace=True)\n",
    "    df_forecast[\"PREDICTED_REVENUE\"] = df_forecast[\"PREDICTED_REVENUE\"].astype(\"float\")\n",
    "    return df_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3749373-0500-4df2-8f55-7e5024e7051e",
   "metadata": {},
   "source": [
    "First, let's use the `forecast_revenue` function to get the forecast in the date range, based on last year's revenue numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef702a-60da-48a9-b1e6-90982879afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(\"2025-10-01\")\n",
    "end_date = pd.Timestamp(\"2025-10-31\")\n",
    "df_forecast = forecast_revenue(df_transactions, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276513a5-bcad-4c41-bec0-585ebc5690a4",
   "metadata": {},
   "source": [
    "The resulting dataframe is very small, since it is only the 1-month window we're performing forecast on, so the backend is running on pandas locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5cf071-c8be-4543-b3b9-a23b844b18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_forecast.get_backend() == 'Pandas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17271e32-0a0e-47aa-9701-38d35373f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_for_holiday_weekend(row):\n",
    "    # For national holidays, revenue down 5% since stores are closed. For weekends, revenue is up 5% due to increased activity.\n",
    "    if row[\"DATE\"].strftime('%Y-%m-%d') in list(df_us_holidays[\"Date\"].dt.strftime('%Y-%m-%d')): \n",
    "        return row[\"PREDICTED_REVENUE\"] * 0.95\n",
    "    elif row[\"DATE\"].weekday() == 5 or row[\"DATE\"].weekday() == 6: #Saturday/Sundays\n",
    "        return row[\"PREDICTED_REVENUE\"] * 1.05\n",
    "    return row[\"PREDICTED_REVENUE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea50fe2-0633-4b4a-9e51-4cf284b915f1",
   "metadata": {},
   "source": [
    "Now if we run `apply` on this dataframe. It will be running with local pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a06f7-9a55-4d7f-a862-3a73c16b3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust for holidays using the apply function\n",
    "df_forecast[\"PREDICTED_REVENUE\"] = df_forecast.apply(adjust_for_holiday_weekend, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c63b7-885a-4997-a404-ac99bb00aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_forecast.get_backend() == 'Pandas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241afafc-aee4-4c25-8bc9-79c0feba5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HYBRID_DATA_SIZE_TRANSITION_POINT\"] = \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655d2649-8805-4a9d-a7be-a27b95eedcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11928ec40abf4da792ce145bc592e5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transferring data from Pandas to Snowflake ...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_small = pd.DataFrame({'a': [1]*20, 'b': [2]*20}).move_to('Snowflake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c363d9-1c46-447d-8ae0-ffcc478658be",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_small.get_backend() == 'Snowflake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db48d6da-8566-4b12-ae4a-28254c5e7eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switcheroo operation: apply cost to move to pandas: 875 cost to stay: 250\n"
     ]
    }
   ],
   "source": [
    "df_small = df_small.head(15)\n",
    "df_small = df_small.apply(lambda x : x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8327187f-792f-4bed-a179-5faf976c4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_small.get_backend() == 'Snowflake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1425a9-cf16-478b-a461-467c19912729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switcheroo operation: apply cost to move to pandas: 125 cost to stay: 750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dd2a46326a46de963850baecd8b7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transferring data from Snowflake to Pandas ...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_small = df_small.head(5)\n",
    "df_small = df_small.apply(lambda x : x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dae22e1-bc54-4dcf-8448-f1c2e45e2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_small.get_backend() == 'Pandas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bcc492c-6faf-4c2e-9d8a-ab4196397495",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HYBRID_DATA_SIZE_TRANSITION_POINT\"] = \"1000000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1265c3-ef42-428c-8604-a4e5b66fca9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
