{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649e57d-ad7d-4d46-9c65-1055642ca003",
   "metadata": {},
   "source": [
    "From modin main and snowpark python repo: `pip install -e .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f420d4-a934-409c-92b9-29d2427ce6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://snowbiz.okta.com/app/snowflake/exk8wfsfryJIn4IWZ2p7/sso/saml?SAMLRequest=jZJBc9owEIX%2Fikc925INmVANJgOhSdwmQGNcOtyELYMGW3K1cgz99ZXt0EkPyfSmWb0nfbtvxzensnBeuAahZIh8jyCHy1RlQu5DlKzv3BFywDCZsUJJHqIzB3QzGQMri4pOa3OQz%2FxXzcE49iEJtLsIUa0lVQwEUMlKDtSkNJ4%2BPdLAI7TSyqhUFeiN5WMHA%2BDaWMKLJQNh8Q7GVBTjpmm8ZuApvccBIQSTz9iqWsmni%2F5ke3pH72MybPVWYeWrV7aZkP0IPsLa9SKgD%2Bv1yl0t4zVyphfUWyWhLrmOuX4RKU%2BeH3sAsATxYrl5WCbxFw%2BkavKCHXmqyqo29jXPnnDOM1yovbANR%2FMQVUeR%2FczFYkfKxQiazeCQHGfVZpN828M2yhaz09ZMd9U8vR%2Bw%2B9n3FDk%2FLokGbaIRQM0j2eZobIkEVy4ZuiRYB4T613QQeFe%2Bv0XO3OYoJDOd8wLbIu7Eb08dDevgWFXhv9yYn46jJodcn79GchhttkF1jQEUbmNF%2FabQDkBP%2Frf%2FMX7rel22hZ1%2FNF%2BpQqRn507pkpn34%2FE9v6uIzM07KeUlE8U0yzQHsDEVhWpuNWfG7rTRNUd40v%2F671ZP%2FgA%3D&RelayState=ver%3A1-hint%3A2050348631518-ETMsDgAAAZX4JuFfABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAEEklxxnmLQELDysTNrMPZkIAAACQqpKDYbglCDNlWRyC35%2BUda6SLcYatBZLi9v%2Fu27kaP4wgc5aXt5pZopymdpgIyQK%2FOLSIW7qK7aAdGkE2oNYFBPfG%2BJPZxifrasO0ECFhINtK6sUAQtoe83dkJ4i%2F9OHN0z39Li0uFP6G%2FWVy%2FlfOj3ucFTmaqlfydIeqT1hV2kS1eejnaE%2FrR42g5OZ4qjhABRJT09HegcBQS3542P6T16G%2F%2F%2F2Kw%3D%3D to authenticate...\n"
     ]
    }
   ],
   "source": [
    "import snowflake.snowpark.modin.plugin\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as native_pd\n",
    "from snowflake.snowpark.session import Session; session = Session.builder.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662115d3-ad0a-4fea-88ba-321a03ffdf3c",
   "metadata": {},
   "source": [
    "# Example 1: Start with small dataset perform some processing, then join with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad6a86c-ba58-443e-b48f-80a717eb8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emphemeral dataframe/lookup table \n",
    "# List of U.S. federal holidays\n",
    "us_holidays = [\n",
    "    (\"New Year's Day\", \"2025-01-01\"),\n",
    "    (\"Martin Luther King Jr. Day\", \"2025-01-20\"),\n",
    "    (\"Presidents' Day\", \"2025-02-17\"),\n",
    "    (\"Memorial Day\", \"2025-05-26\"),\n",
    "    (\"Juneteenth National Independence Day\", \"2025-06-19\"),\n",
    "    (\"Independence Day\", \"2025-07-04\"),\n",
    "    (\"Labor Day\", \"2025-09-01\"),\n",
    "    (\"Columbus Day\", \"2025-10-13\"),\n",
    "    (\"Veterans Day\", \"2025-11-11\"),\n",
    "    (\"Thanksgiving Day\", \"2025-11-27\"),\n",
    "    (\"Christmas Day\", \"2025-12-25\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_us_holidays = pd.DataFrame(us_holidays, columns=[\"Holiday\", \"Date\"])\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df_us_holidays[\"Date\"] = pd.to_datetime(df_us_holidays[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de09f690-e4e6-4aa3-bef5-bc96a389c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_us_holidays.get_backend() == 'Pandas'  # with auto, we should expect this to be local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f05b150e-086f-4337-bd50-25db48bbeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns for transformations\n",
    "df_us_holidays[\"Day_of_Week\"] = df_us_holidays[\"Date\"].dt.day_name()\n",
    "df_us_holidays[\"Month\"] = df_us_holidays[\"Date\"].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d304c3-54bc-4ab0-b792-df0e67566819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "      <td>2025-01-20</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Presidents' Day</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>Monday</td>\n",
       "      <td>February</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Memorial Day</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>Monday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juneteenth National Independence Day</td>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Independence Day</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Friday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Labor Day</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>September</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Columbus Day</td>\n",
       "      <td>2025-10-13</td>\n",
       "      <td>Monday</td>\n",
       "      <td>October</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Veterans Day</td>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thanksgiving Day</td>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Holiday       Date Day_of_Week      Month\n",
       "0                         New Year's Day 2025-01-01   Wednesday    January\n",
       "1             Martin Luther King Jr. Day 2025-01-20      Monday    January\n",
       "2                        Presidents' Day 2025-02-17      Monday   February\n",
       "3                           Memorial Day 2025-05-26      Monday        May\n",
       "4   Juneteenth National Independence Day 2025-06-19    Thursday       June\n",
       "5                       Independence Day 2025-07-04      Friday       July\n",
       "6                              Labor Day 2025-09-01      Monday  September\n",
       "7                           Columbus Day 2025-10-13      Monday    October\n",
       "8                           Veterans Day 2025-11-11     Tuesday   November\n",
       "9                       Thanksgiving Day 2025-11-27    Thursday   November\n",
       "10                         Christmas Day 2025-12-25    Thursday   December"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558479c6-11d3-42f0-990a-7914967ab66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Year's Day falls on Wednesday, January 1, 2025.\n",
      "Martin Luther King Jr. Day falls on Monday, January 20, 2025.\n",
      "Presidents' Day falls on Monday, February 17, 2025.\n",
      "Memorial Day falls on Monday, May 26, 2025.\n",
      "Juneteenth National Independence Day falls on Thursday, June 19, 2025.\n",
      "Independence Day falls on Friday, July 4, 2025.\n",
      "Labor Day falls on Monday, September 1, 2025.\n",
      "Columbus Day falls on Monday, October 13, 2025.\n",
      "Veterans Day falls on Tuesday, November 11, 2025.\n",
      "Thanksgiving Day falls on Thursday, November 27, 2025.\n",
      "Christmas Day falls on Thursday, December 25, 2025.\n",
      "CPU times: user 89.8 ms, sys: 8.61 ms, total: 98.4 ms\n",
      "Wall time: 98.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Note that without auto-switching, this took 2.5 min\n",
    "for index, row in df_us_holidays.iterrows():\n",
    "    print(f\"{row['Holiday']} falls on {row['Day_of_Week']}, {row['Month']} {row['Date'].day}, {row['Date'].year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935badca-0c09-48b0-a4a9-503ecf413fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df_us_holidays.move_to(\"pandas\") # remove this once we have auto-switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278e239f-5315-49a5-aa48-b42729f8e58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Year's Day falls on Wednesday, January 1, 2025.\n",
      "Martin Luther King Jr. Day falls on Monday, January 20, 2025.\n",
      "Presidents' Day falls on Monday, February 17, 2025.\n",
      "Memorial Day falls on Monday, May 26, 2025.\n",
      "Juneteenth National Independence Day falls on Thursday, June 19, 2025.\n",
      "Independence Day falls on Friday, July 4, 2025.\n",
      "Labor Day falls on Monday, September 1, 2025.\n",
      "Columbus Day falls on Monday, October 13, 2025.\n",
      "Veterans Day falls on Tuesday, November 11, 2025.\n",
      "Thanksgiving Day falls on Thursday, November 27, 2025.\n",
      "Christmas Day falls on Thursday, December 25, 2025.\n",
      "CPU times: user 106 ms, sys: 4.14 ms, total: 111 ms\n",
      "Wall time: 147 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in pandas_df.iterrows():\n",
    "    print(f\"{row['Holiday']} falls on {row['Day_of_Week']}, {row['Month']} {row['Date'].day}, {row['Date'].year}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a177d5a9-5db6-42c2-a87b-35e8eedac2d0",
   "metadata": {},
   "source": [
    "### Another mini example: generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9835a99f-ac2a-4bab-8b07-2243124aafbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 s, sys: 7.43 s, total: 23 s\n",
      "Wall time: 23.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generate 10 million transactions (This is also very slow with Snowpark pandas)\n",
    "import uuid\n",
    "import pandas\n",
    "dates = pandas.date_range(start=\"2025-01-01\", end=\"2025-12-31\", freq=\"D\")\n",
    "num_transactions = 10000000\n",
    "data = {\n",
    "    \"Transaction_ID\": [str(uuid.uuid4()) for _ in range(num_transactions)],\n",
    "    \"Date\": np.random.choice(dates, num_transactions),\n",
    "    \"Revenue\": np.random.uniform(10, 1000, num_transactions)\n",
    "}\n",
    "df_transactions = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "118dc325-442f-462c-8d1a-ed47a240c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions.get_backend() == \"Pandas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aae1a0-98b3-4c3d-a5f4-4c8d183161a0",
   "metadata": {},
   "source": [
    "### 💡 Automatic switching speeds up loops/iterations on small data + inline creation of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88d966-cd81-400f-b0c5-ceac5731aeba",
   "metadata": {},
   "source": [
    "## Example 2: Demonstrate that when data is prefiltered via SQL, the engine choice changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2367bad-bb23-425c-b4fc-f8b72660bffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(number of rows inserted=10000000)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the following to generate a synthetic dataset with 10M rows of transactions (from 2024-2025 current date)\n",
    "session.sql('''\n",
    "CREATE OR REPLACE TABLE revenue_transactions (\n",
    "    Transaction_ID STRING,\n",
    "    Date DATE,\n",
    "    Revenue FLOAT\n",
    ");''').collect()\n",
    "session.sql('''SET num_days = (SELECT DATEDIFF(DAY, '2024-01-01', CURRENT_DATE));''').collect()\n",
    "session.sql('''INSERT INTO revenue_transactions (Transaction_ID, Date, Revenue)\n",
    "SELECT\n",
    "    UUID_STRING() AS Transaction_ID,\n",
    "    DATEADD(DAY, UNIFORM(0, $num_days, RANDOM()), '2024-01-01') AS Date,\n",
    "    UNIFORM(10, 1000, RANDOM()) AS Revenue\n",
    "FROM TABLE(GENERATOR(ROWCOUNT => 10000000));\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af2a3cd9-7d32-4242-a358-8dd5aee926dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions = pd.read_snowflake(\"REVENUE_TRANSACTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0227e992-54cb-4c72-8fc1-69b69f1c9570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9aa6dde-84db-41a8-9070-3d384a576f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_transactions[\"DATE\"] = pd.to_datetime(df_transactions[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2ae5759-2d39-482c-9fbd-bd937c2fbdfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NativeQueryCompiler' object has no attribute 'snowpark_pandas_api_calls'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_transactions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDATE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mREVENUE\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/_internal/telemetry.py:438\u001b[39m, in \u001b[36msnowpark_pandas_telemetry_method_decorator.<locals>.wrap\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap\u001b[39m(*args, **kwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    433\u001b[39m     \u001b[38;5;66;03m# add a `type: ignore` for this function definition because the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    436\u001b[39m     \u001b[38;5;66;03m# hints in-line here. We'll fix up the type with a `cast` before\u001b[39;00m\n\u001b[32m    437\u001b[39m     \u001b[38;5;66;03m# returning the function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_telemetry_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_standalone_function\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproperty_method_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproperty_method_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/_internal/telemetry.py:370\u001b[39m, in \u001b[36m_telemetry_helper\u001b[39m\u001b[34m(func, args, kwargs, is_standalone_function, property_name, property_method_type)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;66;03m# Not inplace lazy APIs: add curr_api_call to the result\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_snowpark_pandas_dataframe_or_series_type(result):\n\u001b[32m    368\u001b[39m     result._query_compiler.snowpark_pandas_api_calls = (\n\u001b[32m    369\u001b[39m         existing_api_calls\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         + \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_query_compiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msnowpark_pandas_api_calls\u001b[49m\n\u001b[32m    371\u001b[39m         + [curr_api_call]\n\u001b[32m    372\u001b[39m     )\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m need_to_restore_args0_api_calls:\n\u001b[32m    374\u001b[39m         args[\u001b[32m0\u001b[39m]._query_compiler.snowpark_pandas_api_calls = existing_api_calls\n",
      "\u001b[31mAttributeError\u001b[39m: 'NativeQueryCompiler' object has no attribute 'snowpark_pandas_api_calls'"
     ]
    }
   ],
   "source": [
    "df_transactions.groupby(\"DATE\").sum()[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "824036de-5ac8-4990-8ab3-cd164c43eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions.get_backend() == \"Snowflake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cee902a-71d8-412b-83b7-ffbd53b8a4c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ordered_dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/var/folders/93/h72l18b526x6dkpfxhp4zj940000gn/T/ipykernel_61038/2478400332.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Filter to records in last 7 days\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_transactions_filter = pd.read_snowflake(\u001b[33m\"SELECT * FROM revenue_transactions WHERE Date >= DATEADD( 'days', -7, current_date ) and Date < current_date\"\u001b[39m)\n",
      "\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/_internal/telemetry.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    474\u001b[39m         \u001b[38;5;66;03m# function should be of type `T`, but it's too much work to\u001b[39;00m\n\u001b[32m    475\u001b[39m         \u001b[38;5;66;03m# extract the input and output types from T in order to add type\u001b[39;00m\n\u001b[32m    476\u001b[39m         \u001b[38;5;66;03m# hints in-line here. We'll fix up the type with a `cast` before\u001b[39;00m\n\u001b[32m    477\u001b[39m         \u001b[38;5;66;03m# returning the function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         return _telemetry_helper(\n\u001b[32m    479\u001b[39m             func=func,\n\u001b[32m    480\u001b[39m             args=args,\n\u001b[32m    481\u001b[39m             kwargs=kwargs,\n",
      "\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/_internal/telemetry.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(func, args, kwargs, is_standalone_function, property_name, property_method_type)\u001b[39m\n\u001b[32m    360\u001b[39m             query_history=query_history,\n\u001b[32m    361\u001b[39m             api_calls=existing_api_calls + [curr_api_call],\n\u001b[32m    362\u001b[39m             method_call_count=method_call_count,\n\u001b[32m    363\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    365\u001b[39m \n\u001b[32m    366\u001b[39m     \u001b[38;5;66;03m# Not inplace lazy APIs: add curr_api_call to the result\u001b[39;00m\n\u001b[32m    367\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_snowpark_pandas_dataframe_or_series_type(result):\n",
      "\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/_internal/telemetry.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(func, args, kwargs, is_standalone_function, property_name, property_method_type)\u001b[39m\n\u001b[32m    360\u001b[39m             query_history=query_history,\n\u001b[32m    361\u001b[39m             api_calls=existing_api_calls + [curr_api_call],\n\u001b[32m    362\u001b[39m             method_call_count=method_call_count,\n\u001b[32m    363\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    365\u001b[39m \n\u001b[32m    366\u001b[39m     \u001b[38;5;66;03m# Not inplace lazy APIs: add curr_api_call to the result\u001b[39;00m\n\u001b[32m    367\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_snowpark_pandas_dataframe_or_series_type(result):\n",
      "\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/extensions/pd_extensions.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(name_or_query, index_col, columns, relaxed_ordering)\u001b[39m\n\u001b[32m    391\u001b[39m     \"\"\"\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m modin.core.execution.dispatching.factories.dispatcher \u001b[38;5;28;01mimport\u001b[39;00m FactoryDispatcher\n\u001b[32m    393\u001b[39m \n\u001b[32m    394\u001b[39m     snow_df = DataFrame(\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         query_compiler=FactoryDispatcher.get_factory()._read_snowflake(\n\u001b[32m    396\u001b[39m             name_or_query,\n\u001b[32m    397\u001b[39m             index_col=index_col,\n\u001b[32m    398\u001b[39m             columns=columns,\n",
      "\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/io/factories.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         params=_doc_io_method_kwargs_params,\n\u001b[32m     92\u001b[39m         method=\u001b[33m\"read_snowflake\"\u001b[39m,\n\u001b[32m     93\u001b[39m     )\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _read_snowflake(cls, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m cls.io_cls.read_snowflake(*args, **kwargs)\n",
      "\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/io/snow_io.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, name_or_query, index_col, columns, relaxed_ordering)\u001b[39m\n\u001b[32m    217\u001b[39m         \"\"\"\n\u001b[32m    218\u001b[39m         See detailed docstring \u001b[38;5;28;01mand\u001b[39;00m examples \u001b[38;5;28;01min\u001b[39;00m ``read_snowflake`` \u001b[38;5;28;01min\u001b[39;00m frontend layer:\n\u001b[32m    219\u001b[39m         src/snowflake/snowpark/modin/plugin/pd_extensions.py\n\u001b[32m    220\u001b[39m         \"\"\"\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m         return cls.query_compiler_cls.from_snowflake(\n\u001b[32m    222\u001b[39m             name_or_query, index_col, columns, relaxed_ordering=relaxed_ordering\n\u001b[32m    223\u001b[39m         )\n",
      "\u001b[32m~/Desktop/snowpandas/modin/modin/logging/logger_decorator.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m             Any\n\u001b[32m    146\u001b[39m             \"\"\"\n\u001b[32m    147\u001b[39m             start_time = perf_counter()\n\u001b[32m    148\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m LogMode.get() == \u001b[33m\"disable\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m                 result = obj(*args, **kwargs)\n\u001b[32m    150\u001b[39m                 emit_metric(metric_name, perf_counter() - start_time)\n\u001b[32m    151\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    152\u001b[39m \n",
      "\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/compiler/snowflake_query_compiler.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, name_or_query, index_col, columns, relaxed_ordering)\u001b[39m\n\u001b[32m   1144\u001b[39m         \u001b[38;5;66;03m# create ordered dataframe, possibly with all columns in a read only table first\u001b[39;00m\n\u001b[32m   1145\u001b[39m         (\n\u001b[32m   1146\u001b[39m             ordered_dataframe,\n\u001b[32m   1147\u001b[39m             row_position_snowflake_quoted_identifier,\n\u001b[32m-> \u001b[39m\u001b[32m1148\u001b[39m         ) = create_initial_ordered_dataframe(\n\u001b[32m   1149\u001b[39m             table_name_or_query=name_or_query,\n\u001b[32m   1150\u001b[39m             relaxed_ordering=relaxed_ordering,\n\u001b[32m   1151\u001b[39m         )\n",
      "\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/_internal/utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(table_name_or_query, relaxed_ordering)\u001b[39m\n\u001b[32m    482\u001b[39m                 \u001b[33mf\"Failed to create Snowpark pandas DataFrame out of query {table_name_or_query} with error {ex}\"\u001b[39m,\n\u001b[32m    483\u001b[39m                 error_code=SnowparkPandasErrorCode.GENERAL_SQL_EXCEPTION.value,\n\u001b[32m    484\u001b[39m             ) from ex\n\u001b[32m    485\u001b[39m         ordered_dataframe = (\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m             snowpark_pandas_df._query_compiler._modin_frame.ordered_dataframe\n\u001b[32m    487\u001b[39m         )\n\u001b[32m    488\u001b[39m         row_position_snowflake_quoted_identifier = (\n\u001b[32m    489\u001b[39m             ordered_dataframe.row_position_snowflake_quoted_identifier\n",
      "\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6295\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6296\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6297\u001b[39m         ):\n\u001b[32m   6298\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6299\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'ordered_dataframe'"
     ]
    }
   ],
   "source": [
    "# Filter to records in last 7 days\n",
    "df_transactions_filter = pd.read_snowflake(\"SELECT * FROM revenue_transactions WHERE Date >= DATEADD( 'days', -7, current_date ) and Date < current_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6e6b5-d640-4a7e-b60b-3eb1fd379bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_transactions_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9acb3c6-cf17-4440-bb87-03e5ae72107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions_filter.get_backend() == \"Pandas\" # This should work once auto switching is on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc6f90-f883-49a8-b850-3bf5cadd31a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_filter.groupby(\"DATE\").sum()[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bba5b-6f50-48d8-85a4-189668a67fa8",
   "metadata": {},
   "source": [
    "### 💡 Automatic switching means that pandas work well for both small and large data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88cfe0-936a-4fa0-ba01-1a7152781d2f",
   "metadata": {},
   "source": [
    "# Example 3: \n",
    "\n",
    "Forecast using last year's transaction data via a custom apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33ef702a-60da-48a9-b1e6-90982879afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(\"2025-10-01\")\n",
    "end_date = pd.Timestamp(\"2025-10-31\")\n",
    "\n",
    "df_transactions_filtered = df_transactions[\n",
    "    (df_transactions[\"DATE\"] >= start_date - pd.Timedelta(days=365)) &\n",
    "    (df_transactions[\"DATE\"] < end_date - pd.Timedelta(days=365))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7b35fbc-9ef2-4e3b-bf3a-6d25b7d2491e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654618"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3dc4720-a2f2-477e-a095-ff4e3e7affb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_filtered_pandas = df_transactions.move_to(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11a7f0e1-3db6-4a6e-97f3-d28e8d28cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting function using df.apply\n",
    "\n",
    "def forecast_revenue(df, start_date, end_date):\n",
    "    # Filter data from last year\n",
    "    df_filtered = df[(df[\"DATE\"] >= start_date - pd.Timedelta(days=365)) & (df[\"DATE\"] < start_date)]\n",
    "    \n",
    "    # Append future dates to daily_avg for prediction\n",
    "    future_dates = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "    df_future = pd.DataFrame({\"DATE\": future_dates})\n",
    "\n",
    "    # Group by DATE and calculate the mean revenue\n",
    "    daily_avg = df_filtered.groupby(\"DATE\")[\"REVENUE\"].mean().reset_index()\n",
    "    \n",
    "    # Merge future dates with predicted revenue, filling missing values\n",
    "    df_forecast = df_future.merge(daily_avg, on=\"DATE\", how=\"left\")\n",
    "\n",
    "    import numpy as np\n",
    "    # Fill missing predicted revenue with overall mean from last year\n",
    "    df_forecast[\"PREDICTED_REVENUE\"] = np.nan\n",
    "    df_forecast[\"PREDICTED_REVENUE\"].fillna(daily_avg[\"REVENUE\"].mean(), inplace=True)\n",
    "    df_forecast[\"PREDICTED_REVENUE\"] = df_forecast[\"PREDICTED_REVENUE\"].astype(\"float\")\n",
    "    return df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f41e2b38-fb3d-4b52-b115-f78048ff483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The current operation leads to materialization and can be slow if the data is large!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NativeQueryCompiler' object has no attribute 'snowpark_pandas_api_calls'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_forecast = \u001b[43mforecast_revenue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_transactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df_forecast\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mforecast_revenue\u001b[39m\u001b[34m(df, start_date, end_date)\u001b[39m\n\u001b[32m      9\u001b[39m df_future = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mDATE\u001b[39m\u001b[33m\"\u001b[39m: future_dates})\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Group by DATE and calculate the mean revenue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m daily_avg = \u001b[43mdf_filtered\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDATE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mREVENUE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.reset_index()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Merge future dates with predicted revenue, filling missing values\u001b[39;00m\n\u001b[32m     15\u001b[39m df_forecast = df_future.merge(daily_avg, on=\u001b[33m\"\u001b[39m\u001b[33mDATE\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/_internal/telemetry.py:438\u001b[39m, in \u001b[36msnowpark_pandas_telemetry_method_decorator.<locals>.wrap\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap\u001b[39m(*args, **kwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    433\u001b[39m     \u001b[38;5;66;03m# add a `type: ignore` for this function definition because the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    436\u001b[39m     \u001b[38;5;66;03m# hints in-line here. We'll fix up the type with a `cast` before\u001b[39;00m\n\u001b[32m    437\u001b[39m     \u001b[38;5;66;03m# returning the function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_telemetry_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_standalone_function\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproperty_method_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproperty_method_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/_internal/telemetry.py:370\u001b[39m, in \u001b[36m_telemetry_helper\u001b[39m\u001b[34m(func, args, kwargs, is_standalone_function, property_name, property_method_type)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;66;03m# Not inplace lazy APIs: add curr_api_call to the result\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_snowpark_pandas_dataframe_or_series_type(result):\n\u001b[32m    368\u001b[39m     result._query_compiler.snowpark_pandas_api_calls = (\n\u001b[32m    369\u001b[39m         existing_api_calls\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         + \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_query_compiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msnowpark_pandas_api_calls\u001b[49m\n\u001b[32m    371\u001b[39m         + [curr_api_call]\n\u001b[32m    372\u001b[39m     )\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m need_to_restore_args0_api_calls:\n\u001b[32m    374\u001b[39m         args[\u001b[32m0\u001b[39m]._query_compiler.snowpark_pandas_api_calls = existing_api_calls\n",
      "\u001b[31mAttributeError\u001b[39m: 'NativeQueryCompiler' object has no attribute 'snowpark_pandas_api_calls'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "df_forecast = forecast_revenue(df_transactions, start_date, end_date)\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4540bcc-4ac0-4891-b790-e661ffbd199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_forecast[\"DATE\"] = df_forecast[\"DATE\"].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17271e32-0a0e-47aa-9701-38d35373f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_for_holiday_weekend(row):\n",
    "    # For national holidays, revenue down 20% since stores are closed. For weekends, revenue is up 20% due to increased activity.\n",
    "    if row[\"DATE\"].strftime('%Y-%m-%d') in list(df_us_holidays[\"Date\"].dt.strftime('%Y-%m-%d')): \n",
    "        return row[\"PREDICTED_REVENUE\"] * 0.8\n",
    "    elif row[\"DATE\"].weekday() == 5 or row[\"DATE\"].weekday() == 6: #Saturday/Sundays\n",
    "        return row[\"PREDICTED_REVENUE\"] * 1.2\n",
    "    return row[\"PREDICTED_REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9572cbbf-e13f-4769-bed7-453e700cbf9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_forecast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_forecast_pandas = \u001b[43mdf_forecast\u001b[49m.move_to(\u001b[33m\"\u001b[39m\u001b[33mpandas\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_forecast' is not defined"
     ]
    }
   ],
   "source": [
    "df_forecast_pandas = df_forecast.move_to(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a06f7-9a55-4d7f-a862-3a73c16b3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust for holidays\n",
    "df_forecast_pandas[\"PREDICTED_REVENUE\"] = df_forecast_pandas.apply(adjust_for_holiday_weekend, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9d3a0-fac6-42c4-97c7-0ed778872ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast[\"PREDICTED_REVENUE\"] = df_forecast.apply(adjust_for_holiday_weekend, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c2438-c408-47da-8915-5ebeb8e923f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a869dc-cf91-4728-918e-f5dfc6713881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "df_forecast = df_forecast.move_to(\"pandas\")\n",
    "chart_predicted = alt.Chart(df_forecast).mark_line(color='blue').encode(\n",
    "    x='monthdate(DATE):T',\n",
    "    y='PREDICTED_REVENUE:Q',\n",
    "    tooltip=['DATE', 'PREDICTED_REVENUE']\n",
    ").properties(title=\"Predicted Revenue\")\n",
    "chart_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4851c8d-4c0e-432f-a5dd-6f6a897e38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_filtered = df_transactions[\n",
    "    (df_transactions[\"DATE\"] >= start_date - pd.Timedelta(days=365)) &\n",
    "    (df_transactions[\"DATE\"] < end_date - pd.Timedelta(days=365))\n",
    "]\n",
    "df_transactions_filtered_groupby = df_transactions_filtered.groupby(\"DATE\")[\"REVENUE\"].mean()\n",
    "# df_transactions_filtered_groupby = df_transactions_filtered_groupby.move_to(\"pandas\")\n",
    "chart_last_year = alt.Chart(df_transactions_filtered_groupby).mark_line(color='red').encode(\n",
    "    x='monthdate(DATE):T',\n",
    "    y='REVENUE:Q',\n",
    "    tooltip=['DATE', 'REVENUE']\n",
    ").properties(title=\"Last Year Revenue\")\n",
    "\n",
    "# Overlay the charts\n",
    "final_chart = chart_predicted + chart_last_year\n",
    "final_chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
