{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649e57d-ad7d-4d46-9c65-1055642ca003",
   "metadata": {},
   "source": [
    "From modin main and snowpark python repo: `pip install -e .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f420d4-a934-409c-92b9-29d2427ce6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://snowbiz.okta.com/app/snowflake/exk8wfsfryJIn4IWZ2p7/sso/saml?SAMLRequest=jVLRctowEPwVj%2FqMJbvQEA2QcQMM7tBAsWmmeRO2IBrbktHJMe7XVzaQSR6S6ZvmtHu7d3uju1OROy9cg1ByjDyXIIfLRKVCHsZoG897Q%2BSAYTJluZJ8jBoO6G4yAlbkJQ0q8yw3%2FFhxMI5tJIG2H2NUaUkVAwFUsoIDNQmNgp9L6ruEMgCujZVDF0oKwmo9G1NSjOu6duuvrtIH7BNCMLnFFtVCvqA3EuXnGqVWRiUqv1JOdqYPJDxM%2Bq2ERViF9YX4XcjzCj5T2Z1BQBdxvO6tV1GMnOA63b2SUBVcR1y%2FiIRvN8uzAbAOoofV42K1jWYuSFXvc5bxRBVlZWw3177wnqc4VwdhdxROx6jMRHoaNMntfJc1u2q15HpB%2FvyKi%2BNxOTuAt6rFRmdROJtXwJsgQc7va6J%2Bm2gIUPFQtjkaWyL%2BoEf6PeLHvkf7A%2BoN3f63myfkTG2OQjLTMa9mW4s78ddVmWGdOVaW%2BNU35qdsWO9hr5sfoeyHj09%2BeYMBFG5jQudLoZ0BPfnf%2BUf4LetybA92%2F%2BF0rXKRNM5c6YKZj%2BPxXK%2BriLS376CUF0zkQZpqDmBjynNV32vOjL1poyuO8OSs%2Bv6qJ%2F8A&RelayState=ver%3A1-hint%3A2050348631518-ETMsDgAAAZX4dzuDABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAEIsgjQiK0xeeebcWxDEXFxYAAACQn%2BW59ckUXtoJ9zxkPfaUPD8UjOiL068rMLb72KNpcKQk7O0kKGNV4wJcGn%2BN8SboTlPmihx0uOaMXZ0wSL%2Frsqez7DEXA1J72npppuFIMunZCBuN6GDSzc91wnvrR8bhb53zThJCXXdWeuOZn6Ac5KCClqdbg9U8zbVm%2BetZ2X1ag75dSuNBdauYx1HGhm2kABR9QtxeXZdHujBakOJQsBhg%2Brv8kA%3D%3D to authenticate...\n"
     ]
    }
   ],
   "source": [
    "import snowflake.snowpark.modin.plugin\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as native_pd\n",
    "from snowflake.snowpark.session import Session; session = Session.builder.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662115d3-ad0a-4fea-88ba-321a03ffdf3c",
   "metadata": {},
   "source": [
    "# Example 1: Start with small dataset perform some processing, then join with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad6a86c-ba58-443e-b48f-80a717eb8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emphemeral dataframe/lookup table \n",
    "# List of U.S. federal holidays\n",
    "us_holidays = [\n",
    "    (\"New Year's Day\", \"2025-01-01\"),\n",
    "    (\"Martin Luther King Jr. Day\", \"2025-01-20\"),\n",
    "    (\"Presidents' Day\", \"2025-02-17\"),\n",
    "    (\"Memorial Day\", \"2025-05-26\"),\n",
    "    (\"Juneteenth National Independence Day\", \"2025-06-19\"),\n",
    "    (\"Independence Day\", \"2025-07-04\"),\n",
    "    (\"Labor Day\", \"2025-09-01\"),\n",
    "    (\"Columbus Day\", \"2025-10-13\"),\n",
    "    (\"Veterans Day\", \"2025-11-11\"),\n",
    "    (\"Thanksgiving Day\", \"2025-11-27\"),\n",
    "    (\"Christmas Day\", \"2025-12-25\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_us_holidays = pd.DataFrame(us_holidays, columns=[\"Holiday\", \"Date\"])\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df_us_holidays[\"Date\"] = pd.to_datetime(df_us_holidays[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de09f690-e4e6-4aa3-bef5-bc96a389c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_us_holidays.get_backend() == 'Pandas'  # with auto, we should expect this to be local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f05b150e-086f-4337-bd50-25db48bbeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns for transformations\n",
    "df_us_holidays[\"Day_of_Week\"] = df_us_holidays[\"Date\"].dt.day_name()\n",
    "df_us_holidays[\"Month\"] = df_us_holidays[\"Date\"].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d304c3-54bc-4ab0-b792-df0e67566819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "      <td>2025-01-20</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Presidents' Day</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>Monday</td>\n",
       "      <td>February</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Memorial Day</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>Monday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juneteenth National Independence Day</td>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Independence Day</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Friday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Labor Day</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>September</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Columbus Day</td>\n",
       "      <td>2025-10-13</td>\n",
       "      <td>Monday</td>\n",
       "      <td>October</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Veterans Day</td>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thanksgiving Day</td>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Holiday       Date Day_of_Week      Month\n",
       "0                         New Year's Day 2025-01-01   Wednesday    January\n",
       "1             Martin Luther King Jr. Day 2025-01-20      Monday    January\n",
       "2                        Presidents' Day 2025-02-17      Monday   February\n",
       "3                           Memorial Day 2025-05-26      Monday        May\n",
       "4   Juneteenth National Independence Day 2025-06-19    Thursday       June\n",
       "5                       Independence Day 2025-07-04      Friday       July\n",
       "6                              Labor Day 2025-09-01      Monday  September\n",
       "7                           Columbus Day 2025-10-13      Monday    October\n",
       "8                           Veterans Day 2025-11-11     Tuesday   November\n",
       "9                       Thanksgiving Day 2025-11-27    Thursday   November\n",
       "10                         Christmas Day 2025-12-25    Thursday   December"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558479c6-11d3-42f0-990a-7914967ab66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Year's Day falls on Wednesday, January 1, 2025.\n",
      "Martin Luther King Jr. Day falls on Monday, January 20, 2025.\n",
      "Presidents' Day falls on Monday, February 17, 2025.\n",
      "Memorial Day falls on Monday, May 26, 2025.\n",
      "Juneteenth National Independence Day falls on Thursday, June 19, 2025.\n",
      "Independence Day falls on Friday, July 4, 2025.\n",
      "Labor Day falls on Monday, September 1, 2025.\n",
      "Columbus Day falls on Monday, October 13, 2025.\n",
      "Veterans Day falls on Tuesday, November 11, 2025.\n",
      "Thanksgiving Day falls on Thursday, November 27, 2025.\n",
      "Christmas Day falls on Thursday, December 25, 2025.\n",
      "CPU times: user 111 ms, sys: 5.92 ms, total: 117 ms\n",
      "Wall time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Note that without auto-switching, this took 2.5 min\n",
    "for index, row in df_us_holidays.iterrows():\n",
    "    print(f\"{row['Holiday']} falls on {row['Day_of_Week']}, {row['Month']} {row['Date'].day}, {row['Date'].year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935badca-0c09-48b0-a4a9-503ecf413fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df_us_holidays.move_to(\"pandas\") # remove this once we have auto-switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278e239f-5315-49a5-aa48-b42729f8e58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Year's Day falls on Wednesday, January 1, 2025.\n",
      "Martin Luther King Jr. Day falls on Monday, January 20, 2025.\n",
      "Presidents' Day falls on Monday, February 17, 2025.\n",
      "Memorial Day falls on Monday, May 26, 2025.\n",
      "Juneteenth National Independence Day falls on Thursday, June 19, 2025.\n",
      "Independence Day falls on Friday, July 4, 2025.\n",
      "Labor Day falls on Monday, September 1, 2025.\n",
      "Columbus Day falls on Monday, October 13, 2025.\n",
      "Veterans Day falls on Tuesday, November 11, 2025.\n",
      "Thanksgiving Day falls on Thursday, November 27, 2025.\n",
      "Christmas Day falls on Thursday, December 25, 2025.\n",
      "CPU times: user 122 ms, sys: 5.43 ms, total: 127 ms\n",
      "Wall time: 124 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in pandas_df.iterrows():\n",
    "    print(f\"{row['Holiday']} falls on {row['Day_of_Week']}, {row['Month']} {row['Date'].day}, {row['Date'].year}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a177d5a9-5db6-42c2-a87b-35e8eedac2d0",
   "metadata": {},
   "source": [
    "### Another mini example: generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9835a99f-ac2a-4bab-8b07-2243124aafbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 s, sys: 8.75 s, total: 26.7 s\n",
      "Wall time: 26.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generate 10 million transactions (This is also very slow with Snowpark pandas)\n",
    "import uuid\n",
    "import pandas\n",
    "dates = pandas.date_range(start=\"2025-01-01\", end=\"2025-12-31\", freq=\"D\")\n",
    "num_transactions = 10000000\n",
    "data = {\n",
    "    \"Transaction_ID\": [str(uuid.uuid4()) for _ in range(num_transactions)],\n",
    "    \"Date\": np.random.choice(dates, num_transactions),\n",
    "    \"Revenue\": np.random.uniform(10, 1000, num_transactions)\n",
    "}\n",
    "df_transactions = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118dc325-442f-462c-8d1a-ed47a240c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions.get_backend() == \"Pandas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aae1a0-98b3-4c3d-a5f4-4c8d183161a0",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Automatic switching speeds up loops/iterations on small data + inline creation of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88d966-cd81-400f-b0c5-ceac5731aeba",
   "metadata": {},
   "source": [
    "## Example 2: Demonstrate that when data is prefiltered via SQL, the engine choice changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2367bad-bb23-425c-b4fc-f8b72660bffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(number of rows inserted=10000000)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the following to generate a synthetic dataset with 10M rows of transactions (from 2024-2025 current date)\n",
    "session.sql('''\n",
    "CREATE OR REPLACE TABLE revenue_transactions (\n",
    "    Transaction_ID STRING,\n",
    "    Date DATE,\n",
    "    Revenue FLOAT\n",
    ");''').collect()\n",
    "session.sql('''SET num_days = (SELECT DATEDIFF(DAY, '2024-01-01', CURRENT_DATE));''').collect()\n",
    "session.sql('''INSERT INTO revenue_transactions (Transaction_ID, Date, Revenue)\n",
    "SELECT\n",
    "    UUID_STRING() AS Transaction_ID,\n",
    "    DATEADD(DAY, UNIFORM(0, $num_days, RANDOM()), '2024-01-01') AS Date,\n",
    "    UNIFORM(10, 1000, RANDOM()) AS Revenue\n",
    "FROM TABLE(GENERATOR(ROWCOUNT => 10000000));\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2a3cd9-7d32-4242-a358-8dd5aee926dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions = pd.read_snowflake(\"REVENUE_TRANSACTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0227e992-54cb-4c72-8fc1-69b69f1c9570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9aa6dde-84db-41a8-9070-3d384a576f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_transactions[\"DATE\"] = pd.to_datetime(df_transactions[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ae5759-2d39-482c-9fbd-bd937c2fbdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df8244a1ff447049c957befe2ef40d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transferring data from Snowflake to Pandas ...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DATE\n",
       "2024-01-01    11091771.0\n",
       "2024-01-02    10997233.0\n",
       "2024-01-03    11016805.0\n",
       "2024-01-04    11233712.0\n",
       "2024-01-05    11167427.0\n",
       "                 ...    \n",
       "2025-03-29    11063159.0\n",
       "2025-03-30    10959584.0\n",
       "2025-03-31    11088967.0\n",
       "2025-04-01    10991139.0\n",
       "2025-04-02    10928739.0\n",
       "Name: REVENUE, Length: 458, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions.groupby(\"DATE\").sum()[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "824036de-5ac8-4990-8ab3-cd164c43eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions.get_backend() == \"Snowflake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cee902a-71d8-412b-83b7-ffbd53b8a4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962e93ba1b0546c9a6f06d8378bbdea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transferring data from Snowflake to Pandas ...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter to records in last 7 days\n",
    "df_transactions_filter = pd.read_snowflake(\"SELECT * FROM revenue_transactions WHERE Date >= DATEADD( 'days', -7, current_date ) and Date < current_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aca6e6b5-d640-4a7e-b60b-3eb1fd379bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152431"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9acb3c6-cf17-4440-bb87-03e5ae72107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions_filter.get_backend() == \"Pandas\" # This should work once auto switching is on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abcc6f90-f883-49a8-b850-3bf5cadd31a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE\n",
       "2025-03-26    11087078.0\n",
       "2025-03-27    10980480.0\n",
       "2025-03-28    10830212.0\n",
       "2025-03-29    11063159.0\n",
       "2025-03-30    10959584.0\n",
       "2025-03-31    11088967.0\n",
       "2025-04-01    10991139.0\n",
       "Name: REVENUE, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_filter.groupby(\"DATE\").sum()[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bba5b-6f50-48d8-85a4-189668a67fa8",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Automatic switching means that pandas work well for both small and large data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88cfe0-936a-4fa0-ba01-1a7152781d2f",
   "metadata": {},
   "source": [
    "# Example 3: \n",
    "\n",
    "Forecast using last year's transaction data via a custom apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33ef702a-60da-48a9-b1e6-90982879afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(\"2025-10-01\")\n",
    "end_date = pd.Timestamp(\"2025-10-31\")\n",
    "\n",
    "df_transactions_filtered = df_transactions[\n",
    "    (df_transactions[\"DATE\"] >= start_date - pd.Timedelta(days=365)) &\n",
    "    (df_transactions[\"DATE\"] < end_date - pd.Timedelta(days=365))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7b35fbc-9ef2-4e3b-bf3a-6d25b7d2491e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654618"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3dc4720-a2f2-477e-a095-ff4e3e7affb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_filtered_pandas = df_transactions.move_to(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11a7f0e1-3db6-4a6e-97f3-d28e8d28cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting function using df.apply\n",
    "\n",
    "def forecast_revenue(df, start_date, end_date):\n",
    "    # Filter data from last year\n",
    "    df_filtered = df[(df[\"DATE\"] >= start_date - pd.Timedelta(days=365)) & (df[\"DATE\"] < start_date)]\n",
    "    \n",
    "    # Append future dates to daily_avg for prediction\n",
    "    future_dates = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "    df_future = pd.DataFrame({\"DATE\": future_dates})\n",
    "\n",
    "    # Group by DATE and calculate the mean revenue\n",
    "    daily_avg = df_filtered.groupby(\"DATE\")[\"REVENUE\"].mean().reset_index()\n",
    "    \n",
    "    # Merge future dates with predicted revenue, filling missing values\n",
    "    df_forecast = df_future.merge(daily_avg, on=\"DATE\", how=\"left\")\n",
    "\n",
    "    import numpy as np\n",
    "    # Fill missing predicted revenue with overall mean from last year\n",
    "    df_forecast[\"PREDICTED_REVENUE\"] = np.nan\n",
    "    df_forecast[\"PREDICTED_REVENUE\"].fillna(daily_avg[\"REVENUE\"].mean(), inplace=True)\n",
    "    df_forecast[\"PREDICTED_REVENUE\"] = df_forecast[\"PREDICTED_REVENUE\"].astype(\"float\")\n",
    "    return df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f41e2b38-fb3d-4b52-b115-f78048ff483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The current operation leads to materialization and can be slow if the data is large!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NativeQueryCompiler' object has no attribute 'snowpark_pandas_api_calls'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_forecast = \u001b[43mforecast_revenue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_transactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df_forecast\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mforecast_revenue\u001b[39m\u001b[34m(df, start_date, end_date)\u001b[39m\n\u001b[32m      9\u001b[39m df_future = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mDATE\u001b[39m\u001b[33m\"\u001b[39m: future_dates})\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Group by DATE and calculate the mean revenue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m daily_avg = \u001b[43mdf_filtered\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDATE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mREVENUE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.reset_index()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Merge future dates with predicted revenue, filling missing values\u001b[39;00m\n\u001b[32m     15\u001b[39m df_forecast = df_future.merge(daily_avg, on=\u001b[33m\"\u001b[39m\u001b[33mDATE\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/_internal/telemetry.py:438\u001b[39m, in \u001b[36msnowpark_pandas_telemetry_method_decorator.<locals>.wrap\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap\u001b[39m(*args, **kwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    433\u001b[39m     \u001b[38;5;66;03m# add a `type: ignore` for this function definition because the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    436\u001b[39m     \u001b[38;5;66;03m# hints in-line here. We'll fix up the type with a `cast` before\u001b[39;00m\n\u001b[32m    437\u001b[39m     \u001b[38;5;66;03m# returning the function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_telemetry_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_standalone_function\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproperty_method_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproperty_method_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/src/snowflake/snowpark/modin/plugin/_internal/telemetry.py:370\u001b[39m, in \u001b[36m_telemetry_helper\u001b[39m\u001b[34m(func, args, kwargs, is_standalone_function, property_name, property_method_type)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;66;03m# Not inplace lazy APIs: add curr_api_call to the result\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_snowpark_pandas_dataframe_or_series_type(result):\n\u001b[32m    368\u001b[39m     result._query_compiler.snowpark_pandas_api_calls = (\n\u001b[32m    369\u001b[39m         existing_api_calls\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         + \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_query_compiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msnowpark_pandas_api_calls\u001b[49m\n\u001b[32m    371\u001b[39m         + [curr_api_call]\n\u001b[32m    372\u001b[39m     )\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m need_to_restore_args0_api_calls:\n\u001b[32m    374\u001b[39m         args[\u001b[32m0\u001b[39m]._query_compiler.snowpark_pandas_api_calls = existing_api_calls\n",
      "\u001b[31mAttributeError\u001b[39m: 'NativeQueryCompiler' object has no attribute 'snowpark_pandas_api_calls'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "df_forecast = forecast_revenue(df_transactions, start_date, end_date)\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4540bcc-4ac0-4891-b790-e661ffbd199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_forecast[\"DATE\"] = df_forecast[\"DATE\"].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17271e32-0a0e-47aa-9701-38d35373f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_for_holiday_weekend(row):\n",
    "    # For national holidays, revenue down 20% since stores are closed. For weekends, revenue is up 20% due to increased activity.\n",
    "    if row[\"DATE\"].strftime('%Y-%m-%d') in list(df_us_holidays[\"Date\"].dt.strftime('%Y-%m-%d')): \n",
    "        return row[\"PREDICTED_REVENUE\"] * 0.8\n",
    "    elif row[\"DATE\"].weekday() == 5 or row[\"DATE\"].weekday() == 6: #Saturday/Sundays\n",
    "        return row[\"PREDICTED_REVENUE\"] * 1.2\n",
    "    return row[\"PREDICTED_REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9572cbbf-e13f-4769-bed7-453e700cbf9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_forecast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_forecast_pandas = \u001b[43mdf_forecast\u001b[49m.move_to(\u001b[33m\"\u001b[39m\u001b[33mpandas\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_forecast' is not defined"
     ]
    }
   ],
   "source": [
    "df_forecast_pandas = df_forecast.move_to(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a06f7-9a55-4d7f-a862-3a73c16b3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust for holidays\n",
    "df_forecast_pandas[\"PREDICTED_REVENUE\"] = df_forecast_pandas.apply(adjust_for_holiday_weekend, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9d3a0-fac6-42c4-97c7-0ed778872ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast[\"PREDICTED_REVENUE\"] = df_forecast.apply(adjust_for_holiday_weekend, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c2438-c408-47da-8915-5ebeb8e923f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a869dc-cf91-4728-918e-f5dfc6713881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "df_forecast = df_forecast.move_to(\"pandas\")\n",
    "chart_predicted = alt.Chart(df_forecast).mark_line(color='blue').encode(\n",
    "    x='monthdate(DATE):T',\n",
    "    y='PREDICTED_REVENUE:Q',\n",
    "    tooltip=['DATE', 'PREDICTED_REVENUE']\n",
    ").properties(title=\"Predicted Revenue\")\n",
    "chart_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4851c8d-4c0e-432f-a5dd-6f6a897e38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_filtered = df_transactions[\n",
    "    (df_transactions[\"DATE\"] >= start_date - pd.Timedelta(days=365)) &\n",
    "    (df_transactions[\"DATE\"] < end_date - pd.Timedelta(days=365))\n",
    "]\n",
    "df_transactions_filtered_groupby = df_transactions_filtered.groupby(\"DATE\")[\"REVENUE\"].mean()\n",
    "# df_transactions_filtered_groupby = df_transactions_filtered_groupby.move_to(\"pandas\")\n",
    "chart_last_year = alt.Chart(df_transactions_filtered_groupby).mark_line(color='red').encode(\n",
    "    x='monthdate(DATE):T',\n",
    "    y='REVENUE:Q',\n",
    "    tooltip=['DATE', 'REVENUE']\n",
    ").properties(title=\"Last Year Revenue\")\n",
    "\n",
    "# Overlay the charts\n",
    "final_chart = chart_predicted + chart_last_year\n",
    "final_chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
