{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649e57d-ad7d-4d46-9c65-1055642ca003",
   "metadata": {},
   "source": [
    "pip install \"snowflake-snowpark-python[modin] @ git+https://github.com/snowflakedb/snowpark-python.git@modin-hybrid-client\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f420d4-a934-409c-92b9-29d2427ce6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://snowbiz.okta.com/app/snowflake/exk8wfsfryJIn4IWZ2p7/sso/saml?SAMLRequest=jVLRctowEPwVj%2FqMJVwoRANkaGgGMyTQYKDDm7AFqMiSq5Ox6ddXNtBJHpLJm%2Ba0e7t3e737MpXeiRsQWvVR0yfI4yrWiVD7PlpGj40u8sAylTCpFe%2BjMwd0P%2BgBS2VGh7k9qBf%2BJ%2BdgPddIAa0%2B%2Big3imoGAqhiKQdqY7oYPk1p4BPKALixTg5dKQkIp3WwNqMYF0XhF199bfY4IIRgcocdqoJ8Qa8kso81MqOtjrW8UUo30zsSTUxalYRDOIX5lfhdqMsKPlLZXkBAx1E0b8xniwh5w9t0D1pBnnKz4OYkYr58mV4MgHOweJ6tx7Pl4ocPShc7yY481mmWW9fNdy%2B84wmWei%2FcjsJRH2VHkSTffpWzTqbacnXYbseH33eTcLOaRgWZpK2jOE1OrHwq4%2B169TNG3uqWaFAlGgLkPFRVjtaVSNBukFaDBFGzQwmh7bbf6pIN8kYuR6GYrZk3s5XFrfjr66NltTmWZfi%2Fb8zLY7fYwc6cJ6FqhetNkHUwgMZVTOhyKbQ2YAafnb%2BHX7Oux%2Fbs9h%2BO5lqK%2BOw9apMy%2B348Tb9ZV0TS2NVQylMm5DBJDAdwMUmpiwfDmXU3bU3OER5cVN9e9eAf&RelayState=ver%3A1-hint%3A2050348631518-ETMsDgAAAZX3ct84ABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAEE%2FjM2brCF8PdTT6ryZORPUAAACQMTjW4PfEqxuufKGNxjwrFGURVP5Y6G3f0rAMPcYnKyjWdvw9cINxh%2BhfyEPB0XFhqQLqRYT27FOdZMLEXzGTkdAlrFancZbYAe2HexJiNhpOBfA4oJUbf%2FFRQZ4eLcPqXbP2463fwWnEFcRg9OhGo4c6rlLuwFWHqXhiETKFaJfEeIegQcIah0JTPTWLQWahABSClUwWsQGYJKBWzsdfp6H1Iq5dXQ%3D%3D to authenticate...\n"
     ]
    }
   ],
   "source": [
    "import snowflake.snowpark.modin.plugin\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as native_pd\n",
    "from snowflake.snowpark.session import Session; session = Session.builder.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662115d3-ad0a-4fea-88ba-321a03ffdf3c",
   "metadata": {},
   "source": [
    "# Example 1: Start with small dataset perform some processing, then join with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad6a86c-ba58-443e-b48f-80a717eb8204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`to_datetime` implementation may have mismatches with pandas:\n",
      "Snowflake automatic format detection is used when a format is not provided.In this case Snowflake's auto format may yield different result values compared to pandas.See https://docs.snowflake.com/en/sql-reference/date-time-input-output#supported-formats-for-auto-detection for details.\n"
     ]
    }
   ],
   "source": [
    "# emphemeral dataframe/lookup table \n",
    "# List of U.S. federal holidays\n",
    "us_holidays = [\n",
    "    (\"New Year's Day\", \"2025-01-01\"),\n",
    "    (\"Martin Luther King Jr. Day\", \"2025-01-20\"),\n",
    "    (\"Presidents' Day\", \"2025-02-17\"),\n",
    "    (\"Memorial Day\", \"2025-05-26\"),\n",
    "    (\"Juneteenth National Independence Day\", \"2025-06-19\"),\n",
    "    (\"Independence Day\", \"2025-07-04\"),\n",
    "    (\"Labor Day\", \"2025-09-01\"),\n",
    "    (\"Columbus Day\", \"2025-10-13\"),\n",
    "    (\"Veterans Day\", \"2025-11-11\"),\n",
    "    (\"Thanksgiving Day\", \"2025-11-27\"),\n",
    "    (\"Christmas Day\", \"2025-12-25\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_us_holidays = pd.DataFrame(us_holidays, columns=[\"Holiday\", \"Date\"])\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df_us_holidays[\"Date\"] = pd.to_datetime(df_us_holidays[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de09f690-e4e6-4aa3-bef5-bc96a389c3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Snowflake'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_holidays.get_backend() # with auto, we should expect this to be local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f05b150e-086f-4337-bd50-25db48bbeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns for transformations\n",
    "df_us_holidays[\"Day_of_Week\"] = df_us_holidays[\"Date\"].dt.day_name()\n",
    "df_us_holidays[\"Month\"] = df_us_holidays[\"Date\"].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4d304c3-54bc-4ab0-b792-df0e67566819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "      <td>2025-01-20</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Presidents' Day</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>Monday</td>\n",
       "      <td>February</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Memorial Day</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>Monday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juneteenth National Independence Day</td>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Independence Day</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Friday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Labor Day</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>September</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Columbus Day</td>\n",
       "      <td>2025-10-13</td>\n",
       "      <td>Monday</td>\n",
       "      <td>October</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Veterans Day</td>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thanksgiving Day</td>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Holiday       Date Day_of_Week      Month\n",
       "0                         New Year's Day 2025-01-01   Wednesday    January\n",
       "1             Martin Luther King Jr. Day 2025-01-20      Monday    January\n",
       "2                        Presidents' Day 2025-02-17      Monday   February\n",
       "3                           Memorial Day 2025-05-26      Monday        May\n",
       "4   Juneteenth National Independence Day 2025-06-19    Thursday       June\n",
       "5                       Independence Day 2025-07-04      Friday       July\n",
       "6                              Labor Day 2025-09-01      Monday  September\n",
       "7                           Columbus Day 2025-10-13      Monday    October\n",
       "8                           Veterans Day 2025-11-11     Tuesday   November\n",
       "9                       Thanksgiving Day 2025-11-27    Thursday   November\n",
       "10                         Christmas Day 2025-12-25    Thursday   December"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "558479c6-11d3-42f0-990a-7914967ab66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DataFrame.iterrows will result eager evaluation and potential data pulling, which is inefficient. For efficient Snowpark pandas usage, consider rewriting the code with an operator (such as DataFrame.apply or DataFrame.applymap) which can work on the entire DataFrame in one shot.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Year's Day falls on Wednesday, January 1, 2025.\n",
      "Martin Luther King Jr. Day falls on Monday, January 20, 2025.\n",
      "Presidents' Day falls on Monday, February 17, 2025.\n",
      "Memorial Day falls on Monday, May 26, 2025.\n",
      "Juneteenth National Independence Day falls on Thursday, June 19, 2025.\n",
      "Independence Day falls on Friday, July 4, 2025.\n",
      "Labor Day falls on Monday, September 1, 2025.\n",
      "Columbus Day falls on Monday, October 13, 2025.\n",
      "Veterans Day falls on Tuesday, November 11, 2025.\n",
      "Thanksgiving Day falls on Thursday, November 27, 2025.\n",
      "Christmas Day falls on Thursday, December 25, 2025.\n",
      "CPU times: user 12 s, sys: 2.09 s, total: 14.1 s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in df_us_holidays.iterrows():\n",
    "    print(f\"{row['Holiday']} falls on {row['Day_of_Week']}, {row['Month']} {row['Date'].day}, {row['Date'].year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935badca-0c09-48b0-a4a9-503ecf413fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df_us_holidays.move_to(\"pandas\") # remove this once we have auto-switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "278e239f-5315-49a5-aa48-b42729f8e58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Year's Day falls on Wednesday, January 1, 2025.\n",
      "Martin Luther King Jr. Day falls on Monday, January 20, 2025.\n",
      "Presidents' Day falls on Monday, February 17, 2025.\n",
      "Memorial Day falls on Monday, May 26, 2025.\n",
      "Juneteenth National Independence Day falls on Thursday, June 19, 2025.\n",
      "Independence Day falls on Friday, July 4, 2025.\n",
      "Labor Day falls on Monday, September 1, 2025.\n",
      "Columbus Day falls on Monday, October 13, 2025.\n",
      "Veterans Day falls on Tuesday, November 11, 2025.\n",
      "Thanksgiving Day falls on Thursday, November 27, 2025.\n",
      "Christmas Day falls on Thursday, December 25, 2025.\n",
      "CPU times: user 48.4 ms, sys: 4.57 ms, total: 53 ms\n",
      "Wall time: 57.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in pandas_df.iterrows():\n",
    "    print(f\"{row['Holiday']} falls on {row['Day_of_Week']}, {row['Month']} {row['Date'].day}, {row['Date'].year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d2d4a-c7f1-4073-a58b-03f0fc7e0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_us_holidays.get_backend() == \"pandas\" # This should work once auto switching is on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d28b5-ac96-4af4-96ec-a9d95b04b26d",
   "metadata": {},
   "source": [
    "```python\n",
    "# Generate 10 million transactions (This is also very slow with Snowpark)\n",
    "import uuid\n",
    "import pandas\n",
    "dates = pandas.date_range(start=\"2025-01-01\", end=\"2025-12-31\", freq=\"D\")\n",
    "num_transactions = 10000000\n",
    "data = {\n",
    "    \"Transaction_ID\": [str(uuid.uuid4()) for _ in range(num_transactions)],\n",
    "    \"Date\": np.random.choice(dates, num_transactions),\n",
    "    \"Revenue\": np.random.uniform(10, 1000, num_transactions)\n",
    "}\n",
    "\n",
    "df_transactions = pd.DataFrame(data)\n",
    "# This step is extremely slow...\n",
    "df_transactions.to_snowflake(\"REVENUE_TRANSACTIONS\", if_exists='replace', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aae1a0-98b3-4c3d-a5f4-4c8d183161a0",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Automatic switching speeds up loops/iterations on small data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88d966-cd81-400f-b0c5-ceac5731aeba",
   "metadata": {},
   "source": [
    "## Example 2: Demonstrate that when data is prefiltered via SQL, the engine choice changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2367bad-bb23-425c-b4fc-f8b72660bffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(number of rows inserted=10000000)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the following to generate a synthetic dataset with 10M rows of transactions (from 2024-2025)\n",
    "session.sql('''\n",
    "CREATE OR REPLACE TABLE revenue_transactions (\n",
    "    Transaction_ID STRING,\n",
    "    Date DATE,\n",
    "    Revenue FLOAT\n",
    ");''').collect()\n",
    "session.sql('''SET num_days = (SELECT DATEDIFF(DAY, '2024-01-01', CURRENT_DATE));''').collect()\n",
    "session.sql('''INSERT INTO revenue_transactions (Transaction_ID, Date, Revenue)\n",
    "SELECT\n",
    "    UUID_STRING() AS Transaction_ID,\n",
    "    DATEADD(DAY, UNIFORM(0, $num_days, RANDOM()), '2024-01-01') AS Date,\n",
    "    UNIFORM(10, 1000, RANDOM()) AS Revenue\n",
    "FROM TABLE(GENERATOR(ROWCOUNT => 10000000));\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af2a3cd9-7d32-4242-a358-8dd5aee926dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions = pd.read_snowflake(\"REVENUE_TRANSACTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0227e992-54cb-4c72-8fc1-69b69f1c9570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9aa6dde-84db-41a8-9070-3d384a576f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions[\"DATE\"] = pd.to_datetime(df_transactions[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2ae5759-2d39-482c-9fbd-bd937c2fbdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE\n",
       "2024-01-01    11150922.0\n",
       "2024-01-02    10873142.0\n",
       "2024-01-03    10939519.0\n",
       "2024-01-04    11020232.0\n",
       "2024-01-05    11051115.0\n",
       "                 ...    \n",
       "2025-03-29    10994881.0\n",
       "2025-03-30    10959097.0\n",
       "2025-03-31    10995883.0\n",
       "2025-04-01    11098534.0\n",
       "2025-04-02    11041780.0\n",
       "Freq: None, Name: REVENUE, Length: 458, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions.groupby(\"DATE\").sum()[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "824036de-5ac8-4990-8ab3-cd164c43eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_transactions.get_backend() == \"Snowflake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8cee902a-71d8-412b-83b7-ffbd53b8a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to records in last 7 days\n",
    "df_transactions_filter = pd.read_snowflake(\"SELECT * FROM revenue_transactions WHERE Date >= DATEADD( 'days', -7, current_date ) and Date < current_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "272f6a4e-2c3b-48dc-93a2-e755c1a6207f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152608"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cefd68ca-eab7-479a-a0ad-6d4db3910f65",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m df_transactions_filter.get_backend() == \u001b[33m\"\u001b[39m\u001b[33mpandas\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# This should work once auto switching is on\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "assert df_transactions_filter.get_backend() == \"pandas\" # This should work once auto switching is on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc6f90-f883-49a8-b850-3bf5cadd31a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_filter.groupby(\"DATE\").sum()[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bba5b-6f50-48d8-85a4-189668a67fa8",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Automatic switching means that pandas work well for both small and large data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88cfe0-936a-4fa0-ba01-1a7152781d2f",
   "metadata": {},
   "source": [
    "# Example 3: \n",
    "\n",
    "Forecast using last year's transaction data via a custom apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb0b67f4-cd5a-4849-9403-cacb9e90ff21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions[\"DATE\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33ef702a-60da-48a9-b1e6-90982879afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(\"2025-10-01\")\n",
    "end_date = pd.Timestamp(\"2025-10-31\")\n",
    "\n",
    "df_transactions_filtered = df_transactions[\n",
    "    (df_transactions[\"DATE\"] >= start_date - pd.Timedelta(days=365)) &\n",
    "    (df_transactions[\"DATE\"] < end_date - pd.Timedelta(days=365))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7b35fbc-9ef2-4e3b-bf3a-6d25b7d2491e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654725"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3dc4720-a2f2-477e-a095-ff4e3e7affb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_filtered_pandas = df_transactions.move_to(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d5d0610e-a0b2-493f-ad79-b5ed62dfc0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2025-01-01\n",
       "1    2025-01-20\n",
       "2    2025-02-17\n",
       "3    2025-05-26\n",
       "4    2025-06-19\n",
       "5    2025-07-04\n",
       "6    2025-09-01\n",
       "7    2025-10-13\n",
       "8    2025-11-11\n",
       "9    2025-11-27\n",
       "10   2025-12-25\n",
       "Name: Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_holidays[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "37fce918-d17c-4cc4-bbdc-78cb280beb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to pandas required since UDF doesn't take Snowpark pandas objects\n",
    "us_holidays = df_us_holidays[\"Date\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "11a7f0e1-3db6-4a6e-97f3-d28e8d28cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting function using df.apply\n",
    "\n",
    "def forecast_revenue(df, start_date, end_date):\n",
    "    # Filter data from last year\n",
    "    df_filtered = df[(df[\"DATE\"] >= start_date - pd.Timedelta(days=365)) & (df[\"DATE\"] < start_date)]\n",
    "    \n",
    "    # Append future dates to daily_avg for prediction\n",
    "    future_dates = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "    df_future = pd.DataFrame({\"DATE\": future_dates})\n",
    "\n",
    "    # Group by DATE and calculate the mean revenue\n",
    "    daily_avg = df_filtered.groupby(\"DATE\")[\"REVENUE\"].mean().reset_index()\n",
    "    \n",
    "    # Merge future dates with predicted revenue, filling missing values\n",
    "    df_forecast = df_future.merge(daily_avg, on=\"DATE\", how=\"left\")\n",
    "\n",
    "    import numpy as np\n",
    "    # Fill missing predicted revenue with overall mean from last year\n",
    "    df_forecast[\"PREDICTED_REVENUE\"] = np.nan\n",
    "    df_forecast[\"PREDICTED_REVENUE\"].fillna(daily_avg[\"REVENUE\"].mean(), inplace=True)\n",
    "    df_forecast[\"PREDICTED_REVENUE\"] = df_forecast[\"PREDICTED_REVENUE\"].astype(\"float\")\n",
    "    return df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f41e2b38-fb3d-4b52-b115-f78048ff483c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>PREDICTED_REVENUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-10-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-10-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-10-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-10-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-10-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-10-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-10-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-10-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-10-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-10-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-10-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-10-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-10-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-10-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-10-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025-10-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-10-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-10-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-10-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-10-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>505.01707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  REVENUE  PREDICTED_REVENUE\n",
       "0  2025-10-01      NaN          505.01707\n",
       "1  2025-10-02      NaN          505.01707\n",
       "2  2025-10-03      NaN          505.01707\n",
       "3  2025-10-04      NaN          505.01707\n",
       "4  2025-10-05      NaN          505.01707\n",
       "5  2025-10-06      NaN          505.01707\n",
       "6  2025-10-07      NaN          505.01707\n",
       "7  2025-10-08      NaN          505.01707\n",
       "8  2025-10-09      NaN          505.01707\n",
       "9  2025-10-10      NaN          505.01707\n",
       "10 2025-10-11      NaN          505.01707\n",
       "11 2025-10-12      NaN          505.01707\n",
       "12 2025-10-13      NaN          505.01707\n",
       "13 2025-10-14      NaN          505.01707\n",
       "14 2025-10-15      NaN          505.01707\n",
       "15 2025-10-16      NaN          505.01707\n",
       "16 2025-10-17      NaN          505.01707\n",
       "17 2025-10-18      NaN          505.01707\n",
       "18 2025-10-19      NaN          505.01707\n",
       "19 2025-10-20      NaN          505.01707\n",
       "20 2025-10-21      NaN          505.01707\n",
       "21 2025-10-22      NaN          505.01707\n",
       "22 2025-10-23      NaN          505.01707\n",
       "23 2025-10-24      NaN          505.01707\n",
       "24 2025-10-25      NaN          505.01707\n",
       "25 2025-10-26      NaN          505.01707\n",
       "26 2025-10-27      NaN          505.01707\n",
       "27 2025-10-28      NaN          505.01707\n",
       "28 2025-10-29      NaN          505.01707\n",
       "29 2025-10-30      NaN          505.01707\n",
       "30 2025-10-31      NaN          505.01707"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "df_forecast = forecast_revenue(df_transactions, start_date, end_date)\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b4540bcc-4ac0-4891-b790-e661ffbd199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_forecast[\"DATE\"] = df_forecast[\"DATE\"].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "17271e32-0a0e-47aa-9701-38d35373f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_for_holiday_weekend(row):\n",
    "    # For national holidays, revenue down 20% since stores are closed. For weekends, revenue is up 20% due to increased activity.\n",
    "    if row[\"DATE\"].strftime('%Y-%m-%d') in list(df_us_holidays[\"Date\"].dt.strftime('%Y-%m-%d')): \n",
    "        return row[\"PREDICTED_REVENUE\"] * 0.8\n",
    "    elif row[\"DATE\"].weekday() == 5 or row[\"DATE\"].weekday() == 6: #Saturday/Sundays\n",
    "        return row[\"PREDICTED_REVENUE\"] * 1.2\n",
    "    return row[\"PREDICTED_REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9572cbbf-e13f-4769-bed7-453e700cbf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast_pandas = df_forecast.move_to(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b17a06f7-9a55-4d7f-a862-3a73c16b3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust for holidays\n",
    "df_forecast_pandas[\"PREDICTED_REVENUE\"] = df_forecast_pandas.apply(adjust_for_holiday_weekend, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "4dc9d3a0-fac6-42c4-97c7-0ed778872ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast[\"PREDICTED_REVENUE\"] = df_forecast.apply(adjust_for_holiday_weekend, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "226c2438-c408-47da-8915-5ebeb8e923f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modin.pandas.dataframe.DataFrame"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "15a869dc-cf91-4728-918e-f5dfc6713881",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NativeQueryCompiler' object has no attribute 'snowpark_pandas_api_calls'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/altair/vegalite/v5/api.py:4033\u001b[39m, in \u001b[36mChart.to_dict\u001b[39m\u001b[34m(self, validate, format, ignore, context)\u001b[39m\n\u001b[32m   4031\u001b[39m     copy.data = core.InlineData(values=[{}])\n\u001b[32m   4032\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Chart, copy).to_dict(**kwds)\n\u001b[32m-> \u001b[39m\u001b[32m4033\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/altair/vegalite/v5/api.py:1998\u001b[39m, in \u001b[36mTopLevelMixin.to_dict\u001b[39m\u001b[34m(self, validate, format, ignore, context)\u001b[39m\n\u001b[32m   1995\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1996\u001b[39m         \u001b[38;5;66;03m# Non-narwhalifiable type supported by Altair, such as dict\u001b[39;00m\n\u001b[32m   1997\u001b[39m         data = original_data\n\u001b[32m-> \u001b[39m\u001b[32m1998\u001b[39m     copy.data = \u001b[43m_prepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1999\u001b[39m     context[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m] = data\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# remaining to_dict calls are not at top level\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/altair/vegalite/v5/api.py:283\u001b[39m, in \u001b[36m_prepare_data\u001b[39m\u001b[34m(data, context)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _is_data_type(data):\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m func := data_transformers.get():\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m         data = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_native\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_through\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;66;03m# convert string input to a URLData\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/altair/vegalite/data.py:42\u001b[39m, in \u001b[36mdefault_data_transformer\u001b[39m\u001b[34m(data, max_rows)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pipe\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimit_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/altair/utils/data.py:335\u001b[39m, in \u001b[36mto_values\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data_native\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, nw.DataFrame):\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     data = \u001b[43msanitize_narwhals_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m: data.rows(named=\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# Should never reach this state as tested by check_data_type\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/altair/utils/core.py:495\u001b[39m, in \u001b[36msanitize_narwhals_dataframe\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    494\u001b[39m         columns.append(name)\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/narwhals/dataframe.py:1303\u001b[39m, in \u001b[36mDataFrame.select\u001b[39m\u001b[34m(self, *exprs, **named_exprs)\u001b[39m\n\u001b[32m   1269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mselect\u001b[39m(\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28mself\u001b[39m: Self,\n\u001b[32m   1271\u001b[39m     *exprs: IntoExpr | Iterable[IntoExpr],\n\u001b[32m   1272\u001b[39m     **named_exprs: IntoExpr,\n\u001b[32m   1273\u001b[39m ) -> Self:\n\u001b[32m   1274\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Select columns from this DataFrame.\u001b[39;00m\n\u001b[32m   1275\u001b[39m \n\u001b[32m   1276\u001b[39m \u001b[33;03m    Arguments:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1301\u001b[39m \u001b[33;03m        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[39;00m\n\u001b[32m   1302\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/narwhals/dataframe.py:171\u001b[39m, in \u001b[36mBaseFrame.select\u001b[39m\u001b[34m(self, *exprs, **named_exprs)\u001b[39m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._with_compliant(\u001b[38;5;28mself\u001b[39m._compliant_frame.aggregate(*compliant_exprs))\n\u001b[32m    167\u001b[39m compliant_exprs = [\n\u001b[32m    168\u001b[39m     compliant_expr.broadcast(kind) \u001b[38;5;28;01mif\u001b[39;00m is_scalar_like(kind) \u001b[38;5;28;01melse\u001b[39;00m compliant_expr\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m compliant_expr, kind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(compliant_exprs, kinds)\n\u001b[32m    170\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._with_compliant(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compliant_frame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompliant_exprs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/narwhals/_pandas_like/dataframe.py:533\u001b[39m, in \u001b[36mPandasLikeDataFrame.select\u001b[39m\u001b[34m(self, *exprs)\u001b[39m\n\u001b[32m    531\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._with_native(\u001b[38;5;28mself\u001b[39m.native.\u001b[34m__class__\u001b[39m(), validate_column_names=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    532\u001b[39m new_series = align_series_full_broadcast(*new_series)\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m df = \u001b[43mhorizontal_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnative\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnew_series\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimplementation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._with_native(df, validate_column_names=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/narwhals/_pandas_like/utils.py:155\u001b[39m, in \u001b[36mhorizontal_concat\u001b[39m\u001b[34m(dfs, implementation, backend_version)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m implementation.is_pandas_like():\n\u001b[32m    150\u001b[39m     extra_kwargs = (\n\u001b[32m    151\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mcopy\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[32m    152\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m implementation \u001b[38;5;129;01mis\u001b[39;00m Implementation.PANDAS \u001b[38;5;129;01mand\u001b[39;00m backend_version < (\u001b[32m3\u001b[39m,)\n\u001b[32m    153\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    154\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimplementation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_native_namespace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m    158\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected pandas-like implementation (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPANDAS_LIKE_IMPLEMENTATION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m), found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplementation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/snowflake/snowpark/modin/plugin/_internal/telemetry.py:472\u001b[39m, in \u001b[36msnowpark_pandas_telemetry_standalone_function_decorator.<locals>.wrap\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap\u001b[39m(*args, **kwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# add a `type: ignore` for this function definition because the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    470\u001b[39m     \u001b[38;5;66;03m# hints in-line here. We'll fix up the type with a `cast` before\u001b[39;00m\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# returning the function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_telemetry_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_standalone_function\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpandas/snowpark-python/hybrid/lib/python3.11/site-packages/snowflake/snowpark/modin/plugin/_internal/telemetry.py:364\u001b[39m, in \u001b[36m_telemetry_helper\u001b[39m\u001b[34m(func, args, kwargs, is_standalone_function, property_name, property_method_type)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;66;03m# Not inplace lazy APIs: add curr_api_call to the result\u001b[39;00m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_snowpark_pandas_dataframe_or_series_type(result):\n\u001b[32m    362\u001b[39m     result._query_compiler.snowpark_pandas_api_calls = (\n\u001b[32m    363\u001b[39m         existing_api_calls\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m         + \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_query_compiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msnowpark_pandas_api_calls\u001b[49m\n\u001b[32m    365\u001b[39m         + [curr_api_call]\n\u001b[32m    366\u001b[39m     )\n\u001b[32m    367\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m need_to_restore_args0_api_calls:\n\u001b[32m    368\u001b[39m         args[\u001b[32m0\u001b[39m]._query_compiler.snowpark_pandas_api_calls = existing_api_calls\n",
      "\u001b[31mAttributeError\u001b[39m: 'NativeQueryCompiler' object has no attribute 'snowpark_pandas_api_calls'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "df_forecast = df_forecast.move_to(\"pandas\")\n",
    "chart_predicted = alt.Chart(df_forecast).mark_line(color='blue').encode(\n",
    "    x='monthdate(DATE):T',\n",
    "    y='PREDICTED_REVENUE:Q',\n",
    "    tooltip=['DATE', 'PREDICTED_REVENUE']\n",
    ").properties(title=\"Predicted Revenue\")\n",
    "chart_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4851c8d-4c0e-432f-a5dd-6f6a897e38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_filtered = df_transactions[\n",
    "    (df_transactions[\"DATE\"] >= start_date - pd.Timedelta(days=365)) &\n",
    "    (df_transactions[\"DATE\"] < end_date - pd.Timedelta(days=365))\n",
    "]\n",
    "df_transactions_filtered_groupby = df_transactions_filtered.groupby(\"DATE\")[\"REVENUE\"].mean()\n",
    "# df_transactions_filtered_groupby = df_transactions_filtered_groupby.move_to(\"pandas\")\n",
    "chart_last_year = alt.Chart(df_transactions_filtered_groupby).mark_line(color='red').encode(\n",
    "    x='monthdate(DATE):T',\n",
    "    y='REVENUE:Q',\n",
    "    tooltip=['DATE', 'REVENUE']\n",
    ").properties(title=\"Last Year Revenue\")\n",
    "\n",
    "# Overlay the charts\n",
    "final_chart = chart_predicted + chart_last_year\n",
    "final_chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
