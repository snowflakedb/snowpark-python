{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649e57d-ad7d-4d46-9c65-1055642ca003",
   "metadata": {},
   "source": [
    "From modin main and snowpark python repo: `pip install -e .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f420d4-a934-409c-92b9-29d2427ce6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://snowbiz.okta.com/app/snowflake/exk8wfsfryJIn4IWZ2p7/sso/saml?SAMLRequest=jVJdb6MwEPwryPcMBsIpqZWkos31yiltokDaU99cMIkF2K7XhKS%2F%2Fkw%2BTr2HVvdmrWd2Znd2fL1vamfHNHApJijwfOQwkcuCi80ErbM7d4QcMFQUtJaCTdCBAbqejoE2tSJxa7Zixd5aBsaxjQSQ%2FmOCWi2IpMCBCNowICYnafwwJ6HnEwrAtLFy6EwpgFutrTGKYNx1ndcNPKk3OPR9H%2FtX2KJ6yDf0QUJ9raG0NDKX9YWytzN9IhFgP%2BolLMIqLM%2FEGy5OK%2FhK5fUEAnKfZUt3uUgz5MSX6W6lgLZhOmV6x3O2Xs1PBsA6SB8Xz%2FeLdfrDAyG7sqYVy2WjWmO7efaFS1bgWm643VEymyBV8WKX0nhFjVJws6A%2FI%2F6kYnOVdAHlb%2B8qnM3b33ROt4e4qrocOU%2BXRMM%2B0QSgZYnoczS25IffXT9y%2FUEWDEk0JIPIG4XRC3JmNkcuqDkyL2Z7i6%2F83ZOVoUdzVCn81zdm%2B2rUlVDqw69ERMnzS6iGGEDiPiZ0uhRyNKCn%2Fzv%2FGH9knY%2Ft0e4%2FmS1lzfODcyd1Q83n8QRecKzwwi2PUMIayuu4KDQDsDHVtexuNaPG3rTRLUN4elL996qnfwA%3D&RelayState=ver%3A1-hint%3A2050348631518-ETMsDgAAAZX8w%2FIoABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAEL2%2FJmIJYLqcDmZzwupskj0AAACQZTh9gLCTZ56oL2SNLjJFKOzNFKbHBRM2%2BGtUhDoFz6i58owGnJp3Ssm%2FHZPZvpvGTD%2FXGyRQoYVbRNpymyLKXwt6zEcYsLNEfTE9SEDFV2CZIIMVtll4kU7RcPdWuo2yf4uV1laVzJH2VCynC4rRNhJYs99%2Fd%2FFV1MPnfXxzBPzblvPAvHkruVeXvGYCTjzWABTyIjVh9A6rzDvavUImC0nd%2FLWwzg%3D%3D to authenticate...\n"
     ]
    }
   ],
   "source": [
    "import snowflake.snowpark.modin.plugin\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as native_pd\n",
    "from snowflake.snowpark.session import Session; session = Session.builder.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662115d3-ad0a-4fea-88ba-321a03ffdf3c",
   "metadata": {},
   "source": [
    "# Example 1: Start with small dataset perform some processing, then join with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad6a86c-ba58-443e-b48f-80a717eb8204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`to_datetime` implementation may have mismatches with pandas:\n",
      "Snowflake automatic format detection is used when a format is not provided.In this case Snowflake's auto format may yield different result values compared to pandas.See https://docs.snowflake.com/en/sql-reference/date-time-input-output#supported-formats-for-auto-detection for details.\n"
     ]
    }
   ],
   "source": [
    "# emphemeral dataframe/lookup table \n",
    "# List of U.S. federal holidays\n",
    "us_holidays = [\n",
    "    (\"New Year's Day\", \"2025-01-01\"),\n",
    "    (\"Martin Luther King Jr. Day\", \"2025-01-20\"),\n",
    "    (\"Presidents' Day\", \"2025-02-17\"),\n",
    "    (\"Memorial Day\", \"2025-05-26\"),\n",
    "    (\"Juneteenth National Independence Day\", \"2025-06-19\"),\n",
    "    (\"Independence Day\", \"2025-07-04\"),\n",
    "    (\"Labor Day\", \"2025-09-01\"),\n",
    "    (\"Columbus Day\", \"2025-10-13\"),\n",
    "    (\"Veterans Day\", \"2025-11-11\"),\n",
    "    (\"Thanksgiving Day\", \"2025-11-27\"),\n",
    "    (\"Christmas Day\", \"2025-12-25\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_us_holidays = pd.DataFrame(us_holidays, columns=[\"Holiday\", \"Date\"])\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df_us_holidays[\"Date\"] = pd.to_datetime(df_us_holidays[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de09f690-e4e6-4aa3-bef5-bc96a389c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert df_us_holidays.get_backend() == 'Pandas'  # with auto, we should expect this to be local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f05b150e-086f-4337-bd50-25db48bbeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns for transformations\n",
    "df_us_holidays[\"Day_of_Week\"] = df_us_holidays[\"Date\"].dt.day_name()\n",
    "df_us_holidays[\"Month\"] = df_us_holidays[\"Date\"].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d304c3-54bc-4ab0-b792-df0e67566819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "      <td>2025-01-20</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Presidents' Day</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>Monday</td>\n",
       "      <td>February</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Memorial Day</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>Monday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juneteenth National Independence Day</td>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Independence Day</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Friday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Labor Day</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>September</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Columbus Day</td>\n",
       "      <td>2025-10-13</td>\n",
       "      <td>Monday</td>\n",
       "      <td>October</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Veterans Day</td>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thanksgiving Day</td>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Holiday       Date Day_of_Week      Month\n",
       "0                         New Year's Day 2025-01-01   Wednesday    January\n",
       "1             Martin Luther King Jr. Day 2025-01-20      Monday    January\n",
       "2                        Presidents' Day 2025-02-17      Monday   February\n",
       "3                           Memorial Day 2025-05-26      Monday        May\n",
       "4   Juneteenth National Independence Day 2025-06-19    Thursday       June\n",
       "5                       Independence Day 2025-07-04      Friday       July\n",
       "6                              Labor Day 2025-09-01      Monday  September\n",
       "7                           Columbus Day 2025-10-13      Monday    October\n",
       "8                           Veterans Day 2025-11-11     Tuesday   November\n",
       "9                       Thanksgiving Day 2025-11-27    Thursday   November\n",
       "10                         Christmas Day 2025-12-25    Thursday   December"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558479c6-11d3-42f0-990a-7914967ab66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DataFrame.iterrows will result eager evaluation and potential data pulling, which is inefficient. For efficient Snowpark pandas usage, consider rewriting the code with an operator (such as DataFrame.apply or DataFrame.applymap) which can work on the entire DataFrame in one shot.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Year's Day falls on Wednesday, January 1, 2025.\n",
      "Martin Luther King Jr. Day falls on Monday, January 20, 2025.\n",
      "Presidents' Day falls on Monday, February 17, 2025.\n",
      "Memorial Day falls on Monday, May 26, 2025.\n",
      "Juneteenth National Independence Day falls on Thursday, June 19, 2025.\n",
      "Independence Day falls on Friday, July 4, 2025.\n",
      "Labor Day falls on Monday, September 1, 2025.\n",
      "Columbus Day falls on Monday, October 13, 2025.\n",
      "Veterans Day falls on Tuesday, November 11, 2025.\n",
      "Thanksgiving Day falls on Thursday, November 27, 2025.\n",
      "Christmas Day falls on Thursday, December 25, 2025.\n",
      "CPU times: user 10.7 s, sys: 1.66 s, total: 12.4 s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Note that without auto-switching, this took 2.5 min\n",
    "for index, row in df_us_holidays.iterrows():\n",
    "    print(f\"{row['Holiday']} falls on {row['Day_of_Week']}, {row['Month']} {row['Date'].day}, {row['Date'].year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935badca-0c09-48b0-a4a9-503ecf413fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df_us_holidays #.move_to(\"pandas\") # remove this once we have auto-switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e121e5-5f63-494e-a66a-5a47a24a8d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert pandas_df.get_backend() == 'Pandas' # With auto we expect this to be local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a177d5a9-5db6-42c2-a87b-35e8eedac2d0",
   "metadata": {},
   "source": [
    "### Another mini example: generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9835a99f-ac2a-4bab-8b07-2243124aafbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 11 s, total: 1min 23s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generate 10 million transactions (This is also very slow with Snowpark pandas)\n",
    "import uuid\n",
    "import pandas\n",
    "dates = pandas.date_range(start=\"2025-01-01\", end=\"2025-12-31\", freq=\"D\")\n",
    "num_transactions = 10000000\n",
    "data = {\n",
    "    \"Transaction_ID\": [str(uuid.uuid4()) for _ in range(num_transactions)],\n",
    "    \"Date\": np.random.choice(dates, num_transactions),\n",
    "    \"Revenue\": np.random.uniform(10, 1000, num_transactions)\n",
    "}\n",
    "df_transactions = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118dc325-442f-462c-8d1a-ed47a240c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert df_transactions.get_backend() == \"Pandas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aae1a0-98b3-4c3d-a5f4-4c8d183161a0",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Automatic switching speeds up loops/iterations on small data + inline creation of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88d966-cd81-400f-b0c5-ceac5731aeba",
   "metadata": {},
   "source": [
    "## Example 2: Demonstrate that when data is prefiltered via SQL, the engine choice changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2367bad-bb23-425c-b4fc-f8b72660bffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(number of rows inserted=10000000)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the following to generate a synthetic dataset with 10M rows of transactions (from 2024-2025 current date)\n",
    "session.sql('''\n",
    "CREATE OR REPLACE TABLE revenue_transactions (\n",
    "    Transaction_ID STRING,\n",
    "    Date DATE,\n",
    "    Revenue FLOAT\n",
    ");''').collect()\n",
    "session.sql('''SET num_days = (SELECT DATEDIFF(DAY, '2024-01-01', CURRENT_DATE));''').collect()\n",
    "session.sql('''INSERT INTO revenue_transactions (Transaction_ID, Date, Revenue)\n",
    "SELECT\n",
    "    UUID_STRING() AS Transaction_ID,\n",
    "    DATEADD(DAY, UNIFORM(0, $num_days, RANDOM()), '2024-01-01') AS Date,\n",
    "    UNIFORM(10, 1000, RANDOM()) AS Revenue\n",
    "FROM TABLE(GENERATOR(ROWCOUNT => 10000000));\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af2a3cd9-7d32-4242-a358-8dd5aee926dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions = pd.read_snowflake(\"REVENUE_TRANSACTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0227e992-54cb-4c72-8fc1-69b69f1c9570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ae5759-2d39-482c-9fbd-bd937c2fbdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE\n",
       "2024-01-01    11018582.0\n",
       "2024-01-02    11006386.0\n",
       "2024-01-03    11094540.0\n",
       "2024-01-04    11049593.0\n",
       "2024-01-05    10821843.0\n",
       "                 ...    \n",
       "2025-03-30    11012522.0\n",
       "2025-03-31    11073798.0\n",
       "2025-04-01    11027607.0\n",
       "2025-04-02    11091747.0\n",
       "2025-04-03    10975207.0\n",
       "Name: REVENUE, Length: 459, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions.groupby(\"DATE\").sum()[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "824036de-5ac8-4990-8ab3-cd164c43eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert df_transactions.get_backend() == \"Snowflake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cee902a-71d8-412b-83b7-ffbd53b8a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to records in last 7 days\n",
    "df_transactions_filter = pd.read_snowflake(\"SELECT * FROM revenue_transactions WHERE Date >= DATEADD( 'days', -7, current_date ) and Date < current_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aca6e6b5-d640-4a7e-b60b-3eb1fd379bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152495"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9acb3c6-cf17-4440-bb87-03e5ae72107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert df_transactions_filter.get_backend() == \"Pandas\" # This should work once auto switching is on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abcc6f90-f883-49a8-b850-3bf5cadd31a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE\n",
       "2025-03-27    10985476.0\n",
       "2025-03-28    11067748.0\n",
       "2025-03-29    10948092.0\n",
       "2025-03-30    11012522.0\n",
       "2025-03-31    11073798.0\n",
       "2025-04-01    11027607.0\n",
       "2025-04-02    11091747.0\n",
       "Name: REVENUE, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_filter.groupby(\"DATE\").sum()[\"REVENUE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bba5b-6f50-48d8-85a4-189668a67fa8",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Automatic switching means that pandas work well for both small and large data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88cfe0-936a-4fa0-ba01-1a7152781d2f",
   "metadata": {},
   "source": [
    "# Example 3: \n",
    "\n",
    "Forecast using last year's transaction data via a custom apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33ef702a-60da-48a9-b1e6-90982879afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(\"2025-10-01\")\n",
    "end_date = pd.Timestamp(\"2025-10-31\")\n",
    "\n",
    "df_transactions_filtered = df_transactions[\n",
    "    (df_transactions[\"DATE\"] >= start_date - pd.Timedelta(days=365)) &\n",
    "    (df_transactions[\"DATE\"] < end_date - pd.Timedelta(days=365))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7b35fbc-9ef2-4e3b-bf3a-6d25b7d2491e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653625"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3dc4720-a2f2-477e-a095-ff4e3e7affb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_filtered_pandas = df_transactions #.move_to(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a7f0e1-3db6-4a6e-97f3-d28e8d28cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting function using df.apply\n",
    "\n",
    "def forecast_revenue(df, start_date, end_date):\n",
    "    # Filter data from last year\n",
    "    df_filtered = df[(df[\"DATE\"] >= start_date - pd.Timedelta(days=365)) & (df[\"DATE\"] < start_date)]\n",
    "    \n",
    "    # Append future dates to daily_avg for prediction\n",
    "    future_dates = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "    df_future = pd.DataFrame({\"DATE\": future_dates})\n",
    "\n",
    "    # Group by DATE and calculate the mean revenue\n",
    "    daily_avg = df_filtered.groupby(\"DATE\")[\"REVENUE\"].mean().reset_index()\n",
    "    daily_avg[\"DATE\"] = daily_avg[\"DATE\"].astype('datetime64[ns]')\n",
    "    # Merge future dates with predicted revenue, filling missing values\n",
    "    df_forecast = df_future.merge(daily_avg, on=\"DATE\", how=\"left\")\n",
    "    \n",
    "    import numpy as np\n",
    "    # Fill missing predicted revenue with overall mean from last year\n",
    "    df_forecast[\"PREDICTED_REVENUE\"] = np.nan\n",
    "    df_forecast[\"PREDICTED_REVENUE\"].fillna(daily_avg[\"REVENUE\"].mean(), inplace=True)\n",
    "    df_forecast[\"PREDICTED_REVENUE\"] = df_forecast[\"PREDICTED_REVENUE\"].astype(\"float\")\n",
    "    return df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f41e2b38-fb3d-4b52-b115-f78048ff483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The current operation leads to materialization and can be slow if the data is large!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>PREDICTED_REVENUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-10-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-10-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-10-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-10-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-10-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-10-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-10-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-10-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-10-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-10-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-10-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-10-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-10-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-10-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-10-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025-10-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-10-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-10-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-10-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-10-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.983421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  REVENUE  PREDICTED_REVENUE\n",
       "0  2025-10-01      NaN         504.983421\n",
       "1  2025-10-02      NaN         504.983421\n",
       "2  2025-10-03      NaN         504.983421\n",
       "3  2025-10-04      NaN         504.983421\n",
       "4  2025-10-05      NaN         504.983421\n",
       "5  2025-10-06      NaN         504.983421\n",
       "6  2025-10-07      NaN         504.983421\n",
       "7  2025-10-08      NaN         504.983421\n",
       "8  2025-10-09      NaN         504.983421\n",
       "9  2025-10-10      NaN         504.983421\n",
       "10 2025-10-11      NaN         504.983421\n",
       "11 2025-10-12      NaN         504.983421\n",
       "12 2025-10-13      NaN         504.983421\n",
       "13 2025-10-14      NaN         504.983421\n",
       "14 2025-10-15      NaN         504.983421\n",
       "15 2025-10-16      NaN         504.983421\n",
       "16 2025-10-17      NaN         504.983421\n",
       "17 2025-10-18      NaN         504.983421\n",
       "18 2025-10-19      NaN         504.983421\n",
       "19 2025-10-20      NaN         504.983421\n",
       "20 2025-10-21      NaN         504.983421\n",
       "21 2025-10-22      NaN         504.983421\n",
       "22 2025-10-23      NaN         504.983421\n",
       "23 2025-10-24      NaN         504.983421\n",
       "24 2025-10-25      NaN         504.983421\n",
       "25 2025-10-26      NaN         504.983421\n",
       "26 2025-10-27      NaN         504.983421\n",
       "27 2025-10-28      NaN         504.983421\n",
       "28 2025-10-29      NaN         504.983421\n",
       "29 2025-10-30      NaN         504.983421\n",
       "30 2025-10-31      NaN         504.983421"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "df_forecast = forecast_revenue(df_transactions, start_date, end_date)\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17271e32-0a0e-47aa-9701-38d35373f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_for_holiday_weekend(row):\n",
    "    # For national holidays, revenue down 20% since stores are closed. For weekends, revenue is up 20% due to increased activity.\n",
    "    if row[\"DATE\"].strftime('%Y-%m-%d') in list(df_us_holidays[\"Date\"].dt.strftime('%Y-%m-%d')): \n",
    "        return row[\"PREDICTED_REVENUE\"] * 0.8\n",
    "    elif row[\"DATE\"].weekday() == 5 or row[\"DATE\"].weekday() == 6: #Saturday/Sundays\n",
    "        return row[\"PREDICTED_REVENUE\"] * 1.2\n",
    "    return row[\"PREDICTED_REVENUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9572cbbf-e13f-4769-bed7-453e700cbf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast_pandas = df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b17a06f7-9a55-4d7f-a862-3a73c16b3312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function adjust_for_holiday_weekend passed to apply does not have type annotations, or Snowpark pandas could not extract type annotations. Executing apply in slow code path which may result in decreased performance. To disable this warning and improve performance, consider annotating adjust_for_holiday_weekend with type annotations.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Snowpark pandas only allows native pandas and not Snowpark objects in `apply()`. Instead, try calling `to_pandas()` on any DataFrame or Series objects passed to `apply()`. See Limitations(https://docs.snowflake.com/developer-guide/snowpark/python/pandas-on-snowflake#limitations) section ofthe Snowpark pandas documentation for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/modin/plugin/_internal/apply_utils.py:300\u001b[0m, in \u001b[0;36mcreate_udtf_for_apply_axis_1\u001b[0;34m(row_position_snowflake_quoted_identifier, func, raw, result_type, args, column_index, input_types, session, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m     func_udtf \u001b[38;5;241m=\u001b[39m \u001b[43msp_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mudtf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mApplyFunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPandasDataFrameType\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mLongType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStringType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVariantType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrow_position_snowflake_quoted_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[43mAPPLY_LABEL_COLUMN_QUOTED_IDENTIFIER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[43mAPPLY_VALUE_COLUMN_QUOTED_IDENTIFIER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mPandasDataFrameType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLongType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# We have to use the current pandas version to ensure the behavior consistency\u001b[39;49;00m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpackages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnative_pd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpackages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_default_snowpark_pandas_statement_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func_udtf\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/_internal/utils.py:1063\u001b[0m, in \u001b[0;36mpublicapi.<locals>.call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# TODO: Could modify internal docstring to display that users should not modify the _emit_ast parameter.\u001b[39;00m\n\u001b[0;32m-> 1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/functions.py:9712\u001b[0m, in \u001b[0;36mudtf\u001b[0;34m(handler, output_schema, input_types, name, is_permanent, stage_location, imports, packages, replace, if_not_exists, session, parallel, statement_params, strict, secure, external_access_integrations, secrets, immutable, comment, _emit_ast, **kwargs)\u001b[0m\n\u001b[1;32m   9711\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 9712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mudtf_registration_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9714\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9715\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_permanent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_permanent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstage_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstage_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimports\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpackages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_not_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_not_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9726\u001b[0m \u001b[43m        \u001b[49m\u001b[43msecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexternal_access_integrations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexternal_access_integrations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9728\u001b[0m \u001b[43m        \u001b[49m\u001b[43msecrets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecrets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9729\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimmutable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimmutable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9731\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_emit_ast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_emit_ast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9732\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9733\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/_internal/utils.py:1057\u001b[0m, in \u001b[0;36mpublicapi.<locals>.call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_emit_ast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;66;03m# The caller provided _emit_ast explicitly.\u001b[39;00m\n\u001b[0;32m-> 1057\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_emit_ast\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m is_ast_enabled()\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/udtf.py:700\u001b[0m, in \u001b[0;36mUDTFRegistration.register\u001b[0;34m(self, handler, output_schema, input_types, input_names, name, is_permanent, stage_location, imports, packages, replace, if_not_exists, parallel, strict, secure, external_access_integrations, secrets, immutable, max_batch_size, comment, copy_grants, statement_params, _emit_ast, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;66;03m# register udtf\u001b[39;00m\n\u001b[0;32m--> 700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_register_udtf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstage_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimports\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_not_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43msecure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexternal_access_integrations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexternal_access_integrations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43msecrets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecrets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimmutable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimmutable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_call_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUDTFRegistration.register\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_permanent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_permanent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnative_app_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnative_app_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_grants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_grants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_emit_ast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_emit_ast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/udtf.py:1021\u001b[0m, in \u001b[0;36mUDTFRegistration._do_register_udtf\u001b[0;34m(self, handler, output_schema, input_types, input_names, name, stage_location, imports, packages, replace, if_not_exists, parallel, strict, secure, external_access_integrations, secrets, immutable, max_batch_size, comment, native_app_params, statement_params, api_call_source, skip_upload_on_content_match, is_permanent, copy_grants, _emit_ast, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m input_args \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1012\u001b[0m     UDFColumn(dt, arg_name) \u001b[38;5;28;01mfor\u001b[39;00m dt, arg_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(input_types, arg_names)\n\u001b[1;32m   1013\u001b[0m ]\n\u001b[1;32m   1014\u001b[0m (\n\u001b[1;32m   1015\u001b[0m     handler_name,\n\u001b[1;32m   1016\u001b[0m     code,\n\u001b[1;32m   1017\u001b[0m     all_imports,\n\u001b[1;32m   1018\u001b[0m     all_packages,\n\u001b[1;32m   1019\u001b[0m     upload_file_stage_location,\n\u001b[1;32m   1020\u001b[0m     custom_python_runtime_version_allowed,\n\u001b[0;32m-> 1021\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_imports_and_packages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTempObjectType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTABLE_FUNCTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstage_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimports\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pandas_udf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_dataframe_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_upload_on_content_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_upload_on_content_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_permanent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_permanent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m runtime_version_from_requirement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/_internal/udf_utils.py:1172\u001b[0m, in \u001b[0;36mresolve_imports_and_packages\u001b[0;34m(session, object_type, func, arg_names, udf_name, stage_location, imports, packages, parallel, is_pandas_udf, is_dataframe_input, max_batch_size, statement_params, source_code_display, skip_upload_on_content_match, is_permanent, force_inline_code)\u001b[0m\n\u001b[1;32m   1171\u001b[0m udf_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mudf_file_name_base\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1172\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_python_code\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pandas_udf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_dataframe_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_code_display\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_code_display\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_inline_code \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(code) \u001b[38;5;241m>\u001b[39m _MAX_INLINE_CLOSURE_SIZE_BYTES:\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/_internal/udf_utils.py:846\u001b[0m, in \u001b[0;36mgenerate_python_code\u001b[0;34m(func, arg_names, object_type, is_pandas_udf, is_dataframe_input, max_batch_size, source_code_display)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 846\u001b[0m     pickled_func \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg_names)\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/_internal/udf_utils.py:779\u001b[0m, in \u001b[0;36mpickle_function\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHIGHEST_PROTOCOL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;66;03m# it happens when copying the global object inside the UDF that can't be pickled\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/cloudpickle/cloudpickle.py:1479\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m   1478\u001b[0m cp \u001b[38;5;241m=\u001b[39m Pickler(file, protocol\u001b[38;5;241m=\u001b[39mprotocol, buffer_callback\u001b[38;5;241m=\u001b[39mbuffer_callback)\n\u001b[0;32m-> 1479\u001b[0m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/cloudpickle/cloudpickle.py:1245\u001b[0m, in \u001b[0;36mPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/modin/plugin/utils/error_message.py:117\u001b[0m, in \u001b[0;36m_make_not_implemented_decorator.<locals>.not_implemented_decorator.<locals>.make_error_raiser.<locals>.raise_not_implemented_method_error\u001b[0;34m(cls_or_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     non_null_attribute_prefix \u001b[38;5;241m=\u001b[39m attribute_prefix\n\u001b[0;32m--> 117\u001b[0m \u001b[43mErrorMessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_implemented\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43m_snowpark_pandas_does_not_yet_support\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m method \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnon_null_attribute_prefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/modin/plugin/utils/error_message.py:163\u001b[0m, in \u001b[0;36mErrorMessage.not_implemented\u001b[0;34m(cls, message)\u001b[0m\n\u001b[1;32m    162\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNotImplementedError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(message)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Snowpark pandas does not yet support the method DataFrame.__reduce__",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Adjust for holidays\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_forecast_pandas[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPREDICTED_REVENUE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_forecast_pandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjust_for_holiday_weekend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/modin/plugin/_internal/telemetry.py:432\u001b[0m, in \u001b[0;36msnowpark_pandas_telemetry_method_decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# add a `type: ignore` for this function definition because the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;66;03m# hints in-line here. We'll fix up the type with a `cast` before\u001b[39;00m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# returning the function.\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_telemetry_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_standalone_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproperty_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproperty_method_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproperty_method_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/modin/plugin/_internal/telemetry.py:358\u001b[0m, in \u001b[0;36m_telemetry_helper\u001b[0;34m(func, args, kwargs, is_standalone_function, property_name, property_method_type)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# Send Telemetry and Raise Error\u001b[39;00m\n\u001b[1;32m    346\u001b[0m     _send_snowpark_pandas_telemetry_helper(\n\u001b[1;32m    347\u001b[0m         session\u001b[38;5;241m=\u001b[39msession,\n\u001b[1;32m    348\u001b[0m         telemetry_type\u001b[38;5;241m=\u001b[39merror_to_telemetry_type(e),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m         method_call_count\u001b[38;5;241m=\u001b[39mmethod_call_count,\n\u001b[1;32m    357\u001b[0m     )\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# Not inplace lazy APIs: add curr_api_call to the result\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_snowpark_pandas_dataframe_or_series_type(result):\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/modin/plugin/_internal/telemetry.py:343\u001b[0m, in \u001b[0;36m_telemetry_helper\u001b[0;34m(func, args, kwargs, is_standalone_function, property_name, property_method_type)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# query_history is a QueryHistory instance which is a Context Managers\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# See example in https://github.com/snowflakedb/snowpark-python/blob/main/src/snowflake/snowpark/session.py#L2052\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# Use `nullcontext` to handle `session` lacking `query_history` attribute without raising an exception.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# This prevents telemetry from interfering with regular API calls.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(session, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_history\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)() \u001b[38;5;28;01mas\u001b[39;00m query_history:\n\u001b[0;32m--> 343\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# Send Telemetry and Raise Error\u001b[39;00m\n\u001b[1;32m    346\u001b[0m     _send_snowpark_pandas_telemetry_helper(\n\u001b[1;32m    347\u001b[0m         session\u001b[38;5;241m=\u001b[39msession,\n\u001b[1;32m    348\u001b[0m         telemetry_type\u001b[38;5;241m=\u001b[39merror_to_telemetry_type(e),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m         method_call_count\u001b[38;5;241m=\u001b[39mmethod_call_count,\n\u001b[1;32m    357\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/modin/plugin/extensions/dataframe_overrides.py:810\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# TODO: SNOW-1063346: Modin upgrade - modin.pandas.DataFrame functions\u001b[39;00m\n\u001b[1;32m    809\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m--> 810\u001b[0m query_compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query_compiler, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_compiler)):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;66;03m# A scalar was returned\u001b[39;00m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m query_compiler\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/modin/plugin/compiler/snowflake_query_compiler.py:469\u001b[0m, in \u001b[0;36m_propagate_attrs_on_methods.<locals>.propagate_attrs_decorator.<locals>.wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 469\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, SnowflakeQueryCompiler) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs):\n\u001b[1;32m    471\u001b[0m         result\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs)\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/modin/logging/logger_decorator.py:125\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03mAny\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m logger \u001b[38;5;241m=\u001b[39m get_logger()\n\u001b[1;32m    128\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(log_level, start_line)\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/modin/plugin/compiler/snowflake_query_compiler.py:8829\u001b[0m, in \u001b[0;36mSnowflakeQueryCompiler.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8819\u001b[0m WarningMessage\u001b[38;5;241m.\u001b[39msingle_warning(\n\u001b[1;32m   8820\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed to apply does not have type annotations,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   8821\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or Snowpark pandas could not extract type annotations. Executing apply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8824\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with type annotations.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   8825\u001b[0m )\n\u001b[1;32m   8827\u001b[0m \u001b[38;5;66;03m# Result may need to get expanded into multiple columns, or return type of func is not known.\u001b[39;00m\n\u001b[1;32m   8828\u001b[0m \u001b[38;5;66;03m# Process using UDTF together with dynamic pivot for either case.\u001b[39;00m\n\u001b[0;32m-> 8829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_with_udtf_and_dynamic_pivot_along_axis_1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   8831\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/modin/logging/logger_decorator.py:125\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03mAny\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m logger \u001b[38;5;241m=\u001b[39m get_logger()\n\u001b[1;32m    128\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(log_level, start_line)\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/modin/plugin/compiler/snowflake_query_compiler.py:8037\u001b[0m, in \u001b[0;36mSnowflakeQueryCompiler._apply_with_udtf_and_dynamic_pivot_along_axis_1\u001b[0;34m(self, func, raw, result_type, args, column_index, input_types, partition_size, **kwargs)\u001b[0m\n\u001b[1;32m   8032\u001b[0m row_position_snowflake_quoted_identifier \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   8033\u001b[0m     new_internal_df\u001b[38;5;241m.\u001b[39mrow_position_snowflake_quoted_identifier\n\u001b[1;32m   8034\u001b[0m )\n\u001b[1;32m   8036\u001b[0m \u001b[38;5;66;03m# The apply function is encapsulated in a UDTF and run as a stored procedure on the pandas dataframe.\u001b[39;00m\n\u001b[0;32m-> 8037\u001b[0m func_udtf \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_udtf_for_apply_axis_1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_position_snowflake_quoted_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8042\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8044\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8045\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modin_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mordered_dataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8046\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8047\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8049\u001b[0m \u001b[38;5;66;03m# Let's start with an example to make the following implementation more clear:\u001b[39;00m\n\u001b[1;32m   8050\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   8051\u001b[0m \u001b[38;5;66;03m# We have a Snowpark pandas DataFrame:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8071\u001b[0m \u001b[38;5;66;03m# Calling a (v)UDTF requires a PARTITION BY clause. Here, a vectorized UDF is used (pandas Snowpark types will\u001b[39;00m\n\u001b[1;32m   8072\u001b[0m \u001b[38;5;66;03m# make the UDTF vectorized).\u001b[39;00m\n\u001b[1;32m   8073\u001b[0m partition_identifier \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   8074\u001b[0m     new_internal_df\u001b[38;5;241m.\u001b[39mordered_dataframe\u001b[38;5;241m.\u001b[39mgenerate_snowflake_quoted_identifiers(\n\u001b[1;32m   8075\u001b[0m         pandas_labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartition_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   8076\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   8077\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/non-hybrid/lib/python3.9/site-packages/snowflake/snowpark/modin/plugin/_internal/apply_utils.py:321\u001b[0m, in \u001b[0;36mcreate_udtf_for_apply_axis_1\u001b[0;34m(row_position_snowflake_quoted_identifier, func, raw, result_type, args, column_index, input_types, session, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func_udtf\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# When a Snowpark object is passed to a UDF, a NotImplementedError with message\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# 'Snowpark pandas does not yet support the method DataFrame.__reduce__' is raised. Instead,\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# catch this exception and return a more user-friendly error message.\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(APPLY_WITH_SNOWPARK_OBJECT_ERROR_MSG)\n",
      "\u001b[0;31mValueError\u001b[0m: Snowpark pandas only allows native pandas and not Snowpark objects in `apply()`. Instead, try calling `to_pandas()` on any DataFrame or Series objects passed to `apply()`. See Limitations(https://docs.snowflake.com/developer-guide/snowpark/python/pandas-on-snowflake#limitations) section ofthe Snowpark pandas documentation for more details."
     ]
    }
   ],
   "source": [
    "# Adjust for holidays\n",
    "df_forecast_pandas[\"PREDICTED_REVENUE\"] = df_forecast_pandas.apply(adjust_for_holiday_weekend, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9d3a0-fac6-42c4-97c7-0ed778872ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast[\"PREDICTED_REVENUE\"] = df_forecast.apply(adjust_for_holiday_weekend, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c2438-c408-47da-8915-5ebeb8e923f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a869dc-cf91-4728-918e-f5dfc6713881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "chart_predicted = alt.Chart(df_forecast).mark_line(color='blue').encode(\n",
    "    x='monthdate(DATE):T',\n",
    "    y='PREDICTED_REVENUE:Q',\n",
    "    tooltip=['DATE', 'PREDICTED_REVENUE']\n",
    ").properties(title=\"Predicted Revenue\")\n",
    "chart_predicted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
